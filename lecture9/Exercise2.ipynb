{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第9回: RNN: Exercise2\n",
    "## シェイクスピアをCharacter-Level RNNで学習する\n",
    "### 概要\n",
    "本演習ではChainerを用いてCharacter Level RNNを実装します。\n",
    "\n",
    "まず、講師が概要を説明しますので、全体を掴んだところで演習に取り組んでください。\n",
    "### 目標\n",
    "- ChainerでRNNを実装する\n",
    "- 言語モデルを学習させる\n",
    "- truncated backpropを実装する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### おまじない\n",
    "必要なモジュールをimportしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import chainer\n",
    "from chainer import serializers\n",
    "from chainer import cuda, Function, optimizers\n",
    "from chainer import Link, Chain, ChainList, Variable\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Note:<br>\n",
    "以下でCPU or GPUを使うか選択してください。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport cupy as cp\\nxp = cp  # for GPU computations\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "xp = np  # for CPU computations\n",
    "\n",
    "\"\"\"\n",
    "import cupy as cp\n",
    "xp = cp  # for GPU computations\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Level言語モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ある入力列$x_1, x_2, \\dots, x_t$が与えられたときに、\n",
    "$x_{t+1}$を予測するモデルを文字レベルの言語モデル(character level language model)と呼びます。\n",
    "\n",
    "たとえば、'hello'を学習したCharacter Level言語モデルは、'hell'が与えられたときに、次に現れるアルファベット'o'を予測する事ができます。\n",
    "\n",
    "本演習では、Shakespeareの悲劇の一つである『リア王』を用いて、Character Level Language Modelを学習させてみます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データの構造と前処理\n",
    "### 学習データの構造\n",
    "さて、学習に用いるデータセットは、例えば以下のような文章で構成されています。\n",
    "\n",
    "```\n",
    "BIONDELLO:\n",
    "Marry, that it may not pray their patience.'\n",
    "\n",
    "KING LEAR:\n",
    "The instant common maid, as we may less be\n",
    "a brave gentleman and joiner: he that finds us with wax\n",
    "And owe so full of presence and our fooder at our\n",
    "staves. It is remorsed the bridal's man his grace\n",
    "for every business in my tongue, but I was thinking\n",
    "that he contends, he hath respected thee.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文章を実際に扱うには、幾つかのプログラム上の工夫が必要になります。\n",
    "まず、学習データ中で使用される文字や記号をリカレントニューラルネットワークに入力する際に、これらの文字や記号をベクトルで表記する必要があります。例えば、'b'という文字をネットワークに入力する際には、アルファベットの二番目の文字なので、`...00010`というように、下から2bit目を立たせて表現します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように、記号をネットワークで扱いやすいような\n",
    "分散表現に変換する操作のことをword embeddings(単語の分散表現)と呼びます。\n",
    "実際に言語モデルや翻訳モデルを獲得する際には、\n",
    "このように文字(character)を変換するのではなく、よりまとまった表現として語(word)を分散表現に変換する\n",
    "Word to Vector(W2V)という手法も広く使われることも覚えておくと良いでしょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chainerはこうした文字埋め込みの分散表現が`links.EmbedID`に実装されています。\n",
    "例えば、`abc...xyz`(小文字アルファベット、\n",
    "23文字)から構成される、任意の時系列データを学習させる場合の前処理は、\n",
    "以下のように記述できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example\n",
    "```python\n",
    "embed = L.EmbedID(23, l1_hidden_units)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EmbedIDでは入力をone-hotベクトルとして、次の層に渡す役割を担います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理(preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回使用するデータセットは、アルファベット(大文字、小文字)、\n",
    "及び句読記号(コンマ、コロン、セミコロンなど)にから構成されそうです。\n",
    "\n",
    "実際にデータ・セットを読み込んで確かめてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load text file\n",
    "with open('./data/RNN/shakespear.txt', 'r') as full_text:\n",
    "    full_text = open('./data/RNN/shakespear.txt', 'r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check how it looks like (if you want)\n",
    "# print(full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さて、`list`に格納された`full_text`を学習データセットとして扱うには少し工夫が必要です。\n",
    "\n",
    "すなわち、\n",
    "- 文字をone-hot表現に変換\n",
    "- 段落の終わりを告げる`<EOP>`を導入\n",
    "- 行の終わりを告げる`<EOL>`を導入\n",
    "\n",
    "する必要があります。\n",
    "\n",
    "まず、文字のone-hot表現への変換ですが、これは文字と(uniqueな)IDの一対一対応を持つ辞書を作成すれば良いでしょう。\n",
    "\n",
    "また、`<EOP>`, `<EOS>`の導入も上記の辞書を使用することで解決できますが、\n",
    "これによって、データをネットワークにfeedする際に区切りをつけて処理を行ったり、改行を扱ったりすることが出来ます。\n",
    "\n",
    "この前処理(preprocessing)は、以下のように実装されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symbol = {'<EOL>': 0, '<EOP>': 1}\n",
    "dataset = []\n",
    "for line in full_text:\n",
    "    if line == '\\n':\n",
    "        dataset.append(Variable(xp.array([symbol['<EOP>']], dtype=xp.int32)))\n",
    "        continue\n",
    "    for letter in line.replace('\\n', ''):\n",
    "        if not letter in symbol:\n",
    "            symbol[letter] = len(symbol)\n",
    "        dataset.append(Variable(xp.array([symbol[letter]], dtype=xp.int32)))\n",
    "    dataset.append(Variable(xp.array([symbol['<EOL>']], dtype=xp.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<EOL>': 0, '<EOP>': 1, 'T': 2, 'h': 3, 'a': 4, 't': 5, ',': 6, ' ': 7, 'p': 8, 'o': 9, 'r': 10, 'c': 11, 'n': 12, 'e': 13, 'm': 14, 'l': 15, 'i': 16, \"'\": 17, 'd': 18, 'u': 19, 's': 20, 'f': 21, 'I': 22, 'y': 23, 'v': 24, ';': 25, 'q': 26, 'H': 27, 'b': 28, 'k': 29, 'x': 30, 'A': 31, 'B': 32, 'w': 33, 'g': 34, 'G': 35, '.': 36, 'O': 37, 'N': 38, 'D': 39, 'E': 40, 'L': 41, ':': 42, 'M': 43, 'K': 44, 'R': 45, 'j': 46, 'S': 47, '-': 48, 'F': 49, 'W': 50, 'U': 51, 'Y': 52, 'C': 53, 'V': 54, 'P': 55, '?': 56, '!': 57, 'J': 58, 'X': 59, 'z': 60, 'Q': 61, 'Z': 62}\n"
     ]
    }
   ],
   "source": [
    "# symbol dict: symbols -> id\n",
    "print(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<EOL>', 1: '<EOP>', 2: 'T', 3: 'h', 4: 'a', 5: 't', 6: ',', 7: ' ', 8: 'p', 9: 'o', 10: 'r', 11: 'c', 12: 'n', 13: 'e', 14: 'm', 15: 'l', 16: 'i', 17: \"'\", 18: 'd', 19: 'u', 20: 's', 21: 'f', 22: 'I', 23: 'y', 24: 'v', 25: ';', 26: 'q', 27: 'H', 28: 'b', 29: 'k', 30: 'x', 31: 'A', 32: 'B', 33: 'w', 34: 'g', 35: 'G', 36: '.', 37: 'O', 38: 'N', 39: 'D', 40: 'E', 41: 'L', 42: ':', 43: 'M', 44: 'K', 45: 'R', 46: 'j', 47: 'S', 48: '-', 49: 'F', 50: 'W', 51: 'U', 52: 'Y', 53: 'C', 54: 'V', 55: 'P', 56: '?', 57: '!', 58: 'J', 59: 'X', 60: 'z', 61: 'Q', 62: 'Z'}\n"
     ]
    }
   ],
   "source": [
    "# inv dict: id -> symbols\n",
    "symbol_inv = {v: k for k, v in symbol.items()}\n",
    "print(symbol_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ネットワークに与えられる入力列(dataset)は以下のように、記号に対応したidに置き換えられた形になります"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "[2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 7, 11, 9, ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この入力列は実際には、\n",
    "```python\n",
    "['T', 'h', 'a', 't', ',', ' ', 'p', 'o', 'o', 'r', ' '\n",
    " ```\n",
    "を表しています。(気になる方は以下のサンプルコードを実行してみてください)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# below won't work for gpu\n",
    "# print([v.data[0] for v in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# below won't work for gpu\n",
    "# print([symbol_inv[v.data[0]] for v in dataset][0:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Note:<br>\n",
    "以上がネットワークにどのような情報を与えるのか決める、\n",
    "前処理(preprocessing)の作業となります。\n",
    "言語処理においてどのように前処理を行うのかという問題は、\n",
    "望ましい出力を得るために重要となります。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Level言語モデルを学習するRNNの実装\n",
    "では、実際にCharacter Level Language Modelを学習するRNNを\n",
    "`Chainer`で実装していきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は、学習データの関係上、二層のRNNを使用して実装を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CLRNN(Chain):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input,\n",
    "        n_hidden,\n",
    "        n_output,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize CLRNN\n",
    "        n_input: # of characters\n",
    "        n_hidden: # of hidden units\n",
    "        n_output: # of outputs, equals to # of input in this case\n",
    "        \"\"\"\n",
    "        super(CLRNN, self).__init__()\n",
    "        with self.init_scope():\n",
    "            '''\n",
    "                YOUR CODE HERE\n",
    "            '''\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Forward computation.\n",
    "        x: input vector (in one hot representation)\n",
    "        \"\"\"\n",
    "        x = \"*** YOUR CODE HERE ***\"\n",
    "        h1 = \"*** YOUR CODE HERE ***\"\n",
    "        h2 = \"*** YOUR CODE HERE ***\"\n",
    "        y = \"*** YOUR CODE HERE ***\"\n",
    "        return y\n",
    "    \n",
    "    def reset_state(self):\n",
    "        '''\n",
    "        a function to clear the states in the hidden layer\n",
    "        '''\n",
    "        self.lstm.reset_state()\n",
    "        self.lstm2.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## truncated BPの実装\n",
    "### BPTTの問題\n",
    "非常に長いシークエンスを学習することは、\n",
    "勾配計算をかなり前まで遡らなければならないことを意味します。\n",
    "こうした勾配計算は講義で解説したBPTT(Back Propagation Through Time)\n",
    "として実行されますが、\n",
    "\n",
    "* 計算過程で勾配消失・爆発を引き起こす\n",
    "* (長期にわたる勾配計算では誤差計算を保持しなければならないため)メモリリソースを圧迫する\n",
    "\n",
    "という点で問題があります。\n",
    "これらの問題を解決するために、\n",
    "しばしばバックプロパゲーションを短い時間範囲で切り捨てる場合があります。\n",
    "この手法はtruncated backpropagationと呼ばれます。\n",
    "これはヒューリスティックな手法であり、もちろん切り捨てられた勾配は失われますが、\n",
    "上記のような問題を上手く解決し、結果的に学習効率を向上させることが出来ます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### truncated BP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Chainer`にはtruncated backpropagationの実装として、\n",
    "`Variable.unchain_backward()`というメソッドが実装されています。\n",
    "\n",
    "`Backward Unchaining`は変数から計算履歴(勾配計算)の履歴を断ち切ります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`truncated backpropagation`の例を以下に示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn = CLRNN(\"*** YOUR CODE HERE ***\")\n",
    "model = L.Classifier(rnn)\n",
    "optimizer = optimizers.SGD()\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.links.model.classifier.Classifier at 0x7f8daf0d82b0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !!! FOR GPU !!!\n",
    "gpu_device = 0\n",
    "cuda.get_device(gpu_device).use()\n",
    "model.to_gpu(gpu_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Note:<br>\n",
    "GPUを使用して学習する場合は、上記のコードを実行してください。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train rnn with truncated backpropagation\n",
    "def partial_fit():\n",
    "    loss = 0\n",
    "    count = 0\n",
    "    seqlen = len(dataset)\n",
    "\n",
    "    rnn.reset_state()\n",
    "    trange = tqdm_notebook(\n",
    "        range(seqlen-1),\n",
    "        leave=False\n",
    "    )\n",
    "    for i in trange:\n",
    "        \"*** YOUR CODE HERE ***\"\n",
    "        \"*** YOUR CODE HERE ***\"\n",
    "        loss += model(cur_word, next_word)\n",
    "        count += 1\n",
    "        if count % 100 == 0 or count == seqlen:\n",
    "            model.cleargrads()\n",
    "            loss.backward()\n",
    "            loss.unchain_backward()\n",
    "            optimizer.update()\n",
    "    print('Train Error: {:4f}'.format(float(loss.data)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各ステップでの誤差は`loss`に蓄積されています。\n",
    "今回の実装では、100stepごとに蓄積された誤差に対してバックプロパゲーションを行うと同時に、\n",
    "`loss.unchain_backward()`メソッドを呼び出すことで、\n",
    "蓄積された損失を計算履歴から消去(切り捨て)しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "では実際に学習してみましょう。\n",
    "\n",
    "CLRNNの学習には非常に時間がかかります。学習回数は5-10epoch程度が良いでしょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3603dc1171416f80eb51a1d5b3e629"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97111581bce049b584dbead56e1db2ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-42339dabf712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mepoch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-429d68a53c6e>\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mseqlen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleargrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munchain_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/chainer3/lib/python3.6/site-packages/chainer/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, retain_grad)\u001b[0m\n\u001b[1;32m    707\u001b[0m             func.output_data = tuple(\n\u001b[1;32m    708\u001b[0m                 [None if y is None else y.data for y in outputs])\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0mgxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgxs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_retain_after_backward'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/chainer3/lib/python3.6/site-packages/chainer/functions/connection/embed_id.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, inputs, grad_outputs)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m# too slow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             for ix, igy in six.moves.zip(x.ravel(),\n\u001b[0;32m---> 61\u001b[0;31m                                          gy.reshape(x.size, -1)):\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      "785/|/  1%|| 785/99992 [00:13<29:09, 56.72it/s]"
     ]
    }
   ],
   "source": [
    "epoch_loss = []\n",
    "for i in tqdm_notebook(range(3), leave=False):\n",
    "    epoch_loss.append(partial_fit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 順伝搬の計算\n",
    "### 計算履歴を保存しないネットワーク評価\n",
    "RNNの順伝搬計算で必要なのは、入力及び一時刻前の隠れ層の状態のみで、\n",
    "逆伝搬のように計算履歴をすべて保存する必要はありません。\n",
    "`Chainer`では計算履歴を保存しないForward用の`chainer.config.enable_backprop`という`flag`を用意しています。(Chainer v1で使用されていた`volatile option`はv2で[廃止されました]((http://docs.chainer.org/en/stable/upgrade.html?highlight=volatile#volatile-flag-is-removed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example\n",
    "```python\n",
    "with chainer.no_backprop_mode():\n",
    "    x = Variable(x_data)\n",
    "    feat = fixed_func(x)\n",
    "y = predictor_func(feat)\n",
    "y.backward()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Warning:<br>\n",
    "no_backprop_modeを使用した場合、計算グラフに値が保存されなくなります。それに伴い、loss.backward()は呼び出せなくなります。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、例に習って順伝搬の計算を実装してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn.reset_state()\n",
    "out = []\n",
    "with chainer.no_backprop_mode():\n",
    "    for i in range(10):\n",
    "        rnn(dataset[i])\n",
    "    for i in range(400):\n",
    "        x = Variable(xp.array([rnn(x).data.argmax()], dtype=xp.int32))\n",
    "        out.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e before the say to the say\n",
      "That were shall be despised of thy soul be despiritse a deed, when an his story:\n",
      "The shall be so be soul be despiritse a deed, where he say the fortune and say and say to the speak were and speak with the say\n",
      "That were shall be despised of thy soul be despiritse a deed, when an his story:\n",
      "The shall be so be soul be despiritse a deed, where he say the fortune and say and"
     ]
    }
   ],
   "source": [
    "predicted = [int(o.data) for o in out]\n",
    "for cid in predicted:\n",
    "    if cid == symbol['<EOL>'] or cid==symbol['<EOP>']:\n",
    "        print('')\n",
    "        continue\n",
    "    print(symbol_inv[cid], end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 学習データの読み込み\n",
    "### 学習済みデータの読み込み\n",
    "CLRNNの学習はGPUを使用していても時間がかかります。\n",
    "すでに学習済みのモデルがありますので、そちらを読み込んで遊んでみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事前に学習したモデルは`.npz`という`pickle`形式で保存されています。モデルの読み込みには`chainer.serializers`を使用します。\n",
    "学習した時と同じ設定でインスタンスを作らなければならない点に注意しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_loaded = CLRNN(n_input=len(symbol), n_hidden=1000, n_output=len(symbol))\n",
    "model = L.Classifier(rnn_loaded)\n",
    "serializers.load_npz(\"./data/RNN/clrnn.npz\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contempt, or claim'd thou slept so faithful,\n",
      "I may contrive our father; and, in their defeated queen,\n",
      "Her flesh broke me and puttance of expedition house,\n",
      "And in that same that ever I lament this stomach,\n",
      "And he, nor Butly and my fury, knowing everything\n",
      "Grew daily ever, his great strength and thought\n",
      "The bright buds of mine own.\n",
      "\n",
      "BIONDELLO:\n",
      "Marry, that it may not pray their patience.'\n",
      "\n",
      "KING LEAR:"
     ]
    }
   ],
   "source": [
    "rnn_loaded.reset_state()\n",
    "out = []\n",
    "\"*** YOUR CODE HERE ***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
