# 第5回：勾配法と誤差逆伝播法

## 到達目標
* 基本的な勾配降下法のアルゴリズムを理解する
* ロジスティック回帰における勾配法を実装できる
* フィードフォワードニューラルネットワーク及び誤差逆伝播法の仕組みを理解する
* 指導を受けながら、誤差逆伝播法の実装を体験する

## キーワード
* 勾配降下法
* クロスエントロピー誤差
* フィードフォワードニューラルネットワーク
* 誤差逆伝播法
* 確率的勾配降下法 (SGD)
* ミニバッチ確率的勾配降下法 (MSGD)

## 講師へのお願い
* 生徒のレベル上、偏微分の定義から教える必要があります
* なるべく簡単なデータを用いた例を増やし、数式をコードに落としこむ練習を複数回させてください
* コードの実装は原則1行を埋める方式にとどめ、学習ループの基本的な構造は予め与えてください

## タイムスケジュール
注：今回は、講義->演習->講義->演習という2段形式を取ります。
### 前回の復習 (5分)
### Part 1. ロジスティック回帰と勾配法 (講義、25分)
* 線形回帰の復習
* ロジスティック回帰 (分類問題への拡張)
* シグモイド関数
* クロスエントロピー誤差
* 偏微分の復習 (偏微分の定義と簡単な計算)
* 数値微分と導関数
* (バッチ)勾配降下法
* 1次元データでの勾配法のアルゴリズム (可能であれば、2次元データでの誤差関数の可視化があると良い)
* ニュートン法 (紹介のみ)
* ソフトマックス関数
* 多クラスのクロスエントロピー誤差
* ロジスティック回帰における勾配降下法のアルゴリズム

### 基礎演習:ロジスティック回帰の実装 (演習、15分)
* シグモイド関数の実装
* クロスエントロピー誤差の実装
* 1次元における勾配降下法

### Part 2.フィードフォワードニューラルネットワークと誤差逆伝播法 (講義、25分)
* フィードフォワードニューラルネットワークの定義
* 確率的勾配降下法 (SGD)
* SGDの効果
* 誤差逆伝播法
* 偏微分の連鎖律
* 簡単な加算・乗算に対する誤差逆伝播
* シグモイド関数に対する誤差逆伝播
* 行列計算に対する誤差逆伝播
* SGDにおける順伝播と逆伝播のアルゴリズム
* ミニバッチ勾配降下法 (MBGD)
* ミニバッチ対応版のクロスエントロピー誤差
* ミニバッチ対応版の順伝播・逆伝播アルゴリズム
* ReLU
* NaN対策

### 基礎演習:誤差逆伝播法の練習、導関数の実装 (演習、20分)
* 簡単な計算や、シグモイド関数などのサンプルに対して、誤差逆伝播を手計算する
* シグモイド関数、ソフトマックス関数の導関数を実装する
* (数値部分と比較？)

### 実践演習 (85分)
#### 課題1: ミニバッチ勾配降下法の実装 (20分)
* 3層NN (多層パーセプトロン) に関して予め行列対応版の数式を示し、それを実際に実装する

#### 課題2: MNISTデータセットを用いたニューラルネットの学習 (55分)
* 課題1をMNISTデータセットに対し実際に実行する
* 隠れユニット数、活性化関数、ミニバッチの数を変えて汎化誤差の変化を見る
* 正解率の計算、Learning curveの可視化などは予め用意しておく
* (余裕があれば) Dropout、荷重減衰

#### 解説・コードレビュー (15分)
* できた人のコードを読んで、良い点・改善点があれば指摘
* そのうえで答えの解説

### フィードバック・次回予告 (5分)

## 参考文献 (講師の方も随時追加お願いします)
* 岡谷貴之『機械学習プロフェッショナルシリーズ 深層学習』(講談社、2015)
* C.M.ビショップ『パターン認識と機械学習 上』(丸善出版、2012)
* CS231n: Convolutional Neural Networks for Visual Recognition: Lecture 4
http://vision.stanford.edu/teaching/cs231n/2017/syllabus.html
