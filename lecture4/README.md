# 第4回: scikit-learnを用いたデータ分析

## 到達目標
* Scikit-learnの機能、使い方を理解する。
* サポートベクトルマシン (SVM) の性質と用途を理解し、ライブラリを用いて実際にデータ分類ができる。
* クラスタリング手法の1つとしてK-means法を学び、その性質を理解する。
* XXXデータを題材とした実データの基本的な解析を行える。
* 正規化、次元削減などの前処理の目的とその効果を演習を通じて理解する。
* 数式とコードの関係性について理解を深める。

## 講師へのお願い
解説の濃度を下げて良いので、数式・データがコード上でどのように表現されるのか、どこに注意すればコードが書けるのかを一貫して理解できるようにしてください。

## キーワード
* Scikit-learn
* サポートベクトルマシン
* クラスタリング
* K-means法
* 正規化
* pdb
* (次元削減)
* (主成分分析 (PCA))

## タイムスケジュール
### 前回の復習 (5分)
### 講義(65分)
#### Part 1: 機械学習の代表的なアルゴリズム (40分)
* Scikit-learnの紹介
* Scikit-learnの特長と基本的な使い方 (fit, predict/transform, 簡便なデータロード/セーブ)
* 教師あり学習：サポートベクトルマシン (SVM)
* SVMの問題設定・特長とその用途
* 線形SVM: マージン最大化の観点から (線形、2次元程度の事例について数式及び図示で解説する; 目的関数まで説明して、その最適化については名前を紹介する程度でよい)
* 非線形SVMとカーネルトリック (詳細には立ち入らず、カーネル関数というものを用いることで非線形分類ができることを紹介)
* SVMのscikit-learnでの表現 (問題設定とコードがどのように対応しているか)
* クラスタリングの復習 (第2回で解説予定) とそのユースケースの解説
* K-means法の問題設定・特長と用途、アルゴリズム
* K-means法のscikit-learnでの表現 (問題設定とコードがどのように対応しているか)

#### Part 2: 機械学習の基本テクニック (25分)
* 機械学習の問題設定と目的の再確認 (分類/構造の発見/予測/etc.)
* データの前処理の重要性
* 正規化 (平均0, 分散1)
* 正規化の効果 (K-means法を例に)
* データの観察 (ノイズ・外れ値の削除、例を上げながら、例えばMNISTの難読文字や、人工データで)
* Tokenizationとその用途・方法 (one-hot vector)

以下、余裕があれば
* (次元の呪いと次元削減)
* (次元削減アルゴリズム：主成分分析)
* (データの本質を検討することの重要性)
* (順位尺度などの取り扱い (回帰か、分類か))

### 基礎演習(20分)
* わかりやすい変数名の付け方
* print文を用いたデバッグ (中途の数値及び数値型、形状の確認)
* pdbを用いたデバッグ (pdbのごく基本的な使い方、ステップ実行など)
* 小課題：データの正規化
* 小課題2：人工データにK-means法を適用する

### 実践演習(90分)
#### Part 1: SVMを用いたXXXデータ分類 (題材未定) (40分)
* 何らかのデータを用いて、データを分類
* データ読み込み、可視化は事前提供

#### Part 2: K-means法を用いたXXXデータのクラスタリング (題材未定) (35分)
* 何らかのデータを用いて、クラスタリングを行う
* データ読み込み、可視化は事前提供

#### 解説・コードレビュー (15分)
* できた人のコードを読んで、良い点・改善点があれば指摘
* そのうえで答えの解説

## 参考文献 (講師の方も随時追加お願いします)
### 機械学習によるデータ分析まわりのお話
https://www.slideshare.net/canard0328/ss-44288984
