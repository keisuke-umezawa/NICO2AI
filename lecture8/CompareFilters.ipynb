{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, iterators, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LeNet5(Chain):\n",
    "    def __init__(self, in_channels):\n",
    "        super(LeNet5, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv1 = L.Convolution2D(\n",
    "                in_channels=in_channels, out_channels=6, ksize=5, stride=1)\n",
    "            self.conv2 = L.Convolution2D(\n",
    "                in_channels=6, out_channels=16, ksize=5, stride=1)\n",
    "            self.conv3 = L.Convolution2D(\n",
    "                in_channels=16, out_channels=120, ksize=4, stride=1)\n",
    "            self.fc4 = L.Linear(None, 84)\n",
    "            self.fc5 = L.Linear(84, 10)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.sigmoid(self.conv1(x))\n",
    "        h = F.max_pooling_2d(h, 2, 2)\n",
    "        h = F.sigmoid(self.conv2(h))\n",
    "        h = F.max_pooling_2d(h, 2, 2)\n",
    "        h = F.sigmoid(self.conv3(h))\n",
    "        h = F.sigmoid(self.fc4(h))\n",
    "        if chainer.config.train:\n",
    "            return self.fc5(h)\n",
    "        return F.softmax(self.fc5(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデルをロード\n",
    "ちなみに、20 epoch学習させて、validation accuracyは、\n",
    "\n",
    "| dataset | val_accuracy |\n",
    "| ------- | ------- |\n",
    "| MNIST   | 0.9866 |\n",
    "| CIFAR10 | 0.4835 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_model = L.Classifier(LeNet5(in_channels=1))\n",
    "serializers.save_npz('lenet5-models/mnist.model', mnist_model)\n",
    "\n",
    "cifar10_model = L.Classifier(LeNet5(in_channels=3))\n",
    "serializers.save_npz('lenet5-models/cifar10.model', cifar10_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## フィルタ可視化メソッド"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_conv_layer_weights(weights):\n",
    "    out_n, in_n, h, w = weights.shape\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    for i in range(out_n):\n",
    "        for j in range(in_n):\n",
    "            weight = weights[i, j].data\n",
    "            # ax = fig.add_subplot(out_n, in_n, in_n * i + j + 1, xticks=[], yticks=[])\n",
    "            ax = fig.add_subplot(in_n, out_n, out_n * j + i + 1, xticks=[], yticks=[])\n",
    "            ax.imshow(weight, cmap=plt.cm.gray, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_conv_layer_weights(mnist_model.predictor.conv1.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_conv_layer_weights(cifar10_model.predictor.conv1.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (参考) 学習に使ったコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PreprocessedDataset(chainer.dataset.DatasetMixin):\n",
    "\n",
    "    def __init__(self, base, in_channels, mean):\n",
    "        self.base = base\n",
    "        self.mean = mean.astype('f').reshape((in_channels, 1, 1))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "\n",
    "    def get_example(self, i):\n",
    "        image, label = self.base[i]\n",
    "        image -= self.mean\n",
    "        return image, label\n",
    "\n",
    "\n",
    "def main(target):\n",
    "    if target == 'mnist':\n",
    "        get_dataset = datasets.get_mnist\n",
    "        in_channels = 1\n",
    "    elif target == 'cifar10':\n",
    "        get_dataset = datasets.get_cifar10\n",
    "        in_channels = 3\n",
    "    elif target == 'cifar100':\n",
    "        get_dataset = datasets.get_cifar100\n",
    "        in_channels = 3\n",
    "    else:\n",
    "        print('Invaldi target')\n",
    "        exit()\n",
    "\n",
    "    print('target: {}'.format(target))\n",
    "\n",
    "    train, test = get_dataset(ndim=3)\n",
    "\n",
    "    # Mean subtract\n",
    "    color_mean = train._datasets[0].mean(axis=(0, 2, 3))\n",
    "    train = PreprocessedDataset(train, in_channels=in_channels, mean=color_mean)\n",
    "    test = PreprocessedDataset(test, in_channels=in_channels, mean=color_mean)\n",
    "\n",
    "    train_iter = iterators.SerialIterator(train, batch_size=100, shuffle=True)\n",
    "    test_iter = iterators.SerialIterator(test, batch_size=100, repeat=False, shuffle=False)\n",
    "\n",
    "    model = L.Classifier(LeNet5(in_channels=in_channels))\n",
    "\n",
    "    optimizer = optimizers.Adam()\n",
    "    optimizer.setup(model)\n",
    "\n",
    "    result_dir = 'result/' + target + '_lenet5'\n",
    "\n",
    "    updater = training.StandardUpdater(train_iter, optimizer)\n",
    "    trainer = training.Trainer(updater, (20, 'epoch'), out=result_dir)\n",
    "\n",
    "    trainer.extend(extensions.Evaluator(test_iter, model))\n",
    "    trainer.extend(extensions.LogReport())\n",
    "    trainer.extend(extensions.PrintReport(['epoch', 'main/accuracy', 'validation/main/accuracy']))\n",
    "    trainer.extend(extensions.ProgressBar())\n",
    "\n",
    "    trainer.run()\n",
    "\n",
    "    serializers.save_npz(target + '.model', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
