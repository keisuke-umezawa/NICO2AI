{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実践演習 (85分)\n",
    "#### 課題1: Chainerを用いたCNNの実装 (50分)\n",
    "* MNISTデータセットを用いて、CNNの学習に挑戦\n",
    "* 第6回までの知識と合わせて、正解率99%を目指そう\n",
    "* 使えるツール：畳み込み層、プーリング層、Batch Normalization、SGD、Adam、Dropout\n",
    "\n",
    "#### 課題2a：(パイロット用) Data Augmentation (20分)\n",
    "* Horizontal flippingの実装 (行列のスライス)\n",
    "* Scale augmentation (scipy.misc.imresize)\n",
    "* Random crop/padding (np.pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import\n",
    "お決まりのimport\n",
    "\n",
    "https://docs.chainer.org/en/stable/tutorial/basic.html#core-concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, iterators, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課題1 Chainerを用いたCNNの実装 \n",
    "\n",
    "MNISTデータセットを使って、CNNの学習に挑戦\n",
    "\n",
    "### [appendix] chainer公式documentを見よう！\n",
    "\n",
    "どんなライブラリもそうですが、公式ドキュメント・公式チュートリアルが一番充実しているのです。\n",
    "\n",
    "3-layers MLPによるMNIST学習\n",
    "https://docs.chainer.org/en/stable/tutorial/basic.html#example-multi-layer-perceptron-on-mnist\n",
    "\n",
    "いろいろな画像認識CNNのサンプルコード\n",
    "https://docs.chainer.org/en/stable/tutorial/convnet.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNISTデータセット\n",
    "\n",
    "MNISTデータセットは、かつて画像認識のベンチマークとしてよく使われた、手書き文字データセットです。\n",
    "\n",
    "28x28ピクセル・グレースケールの0~9の数字の手書き文字画像が、学習データ60000枚、テストデータ10000枚含まれています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNISTデータセットの取得\n",
    "\n",
    "データは http://yann.lecun.com/exdb/mnist/ から取得できます。特殊なファイルフォーマット（ページ下部に記載）なので、データ読み取りプログラムを自分でちょちょっと書きますorどこかから貰ってきます。\n",
    "\n",
    "…というのが本来なのですが、chainerが便利メソッドを用意してくれています！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = datasets.get_mnist(ndim=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "どんなデータなのか、少し見てみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "sample_mnist = train[0]\n",
    "\n",
    "plt.imshow(sample_mnist[0][0], cmap='gray')\n",
    "print('Label:', sample_mnist[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNで画像分類サンプル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" このモデルは講師がテキトーに作ったモデルなので、まだまだ良くできます！\n",
    "コードの書き方の参考にしつつ、もっとよいモデルを作ろう！\n",
    "(LeNet5とか試すだけでも大きく伸びます)\n",
    "\"\"\"\n",
    "class SampleCNN(Chain):\n",
    "    def __init__(self):\n",
    "        super(SampleCNN, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv1 = L.Convolution2D(in_channels=1, out_channels=20, ksize=5, stride=1, pad=0)\n",
    "            self.conv2 = L.Convolution2D(in_channels=20, out_channels=50, ksize=5, stride=1, pad=0)\n",
    "            self.l1 = L.Linear(None, 500)\n",
    "            self.l2 = L.Linear(500, 10)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        h = F.max_pooling_2d(self.conv1(x), 2, 2)\n",
    "        h = F.max_pooling_2d(self.conv2(h), 2, 2)\n",
    "        h = F.relu(self.l1(h))\n",
    "        y = F.relu(self.l2(h))\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iter = iterators.SerialIterator(train, batch_size=100, shuffle=True)\n",
    "test_iter = iterators.SerialIterator(test, batch_size=100, repeat=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = L.Classifier(SampleCNN())\n",
    "\n",
    "optimizer = optimizers.SGD()\n",
    "optimizer.setup(model)\n",
    "\n",
    "updater = training.StandardUpdater(train_iter, optimizer)\n",
    "trainer = training.Trainer(updater, (20, 'epoch'), out='result')\n",
    "\n",
    "trainer.extend(extensions.Evaluator(test_iter, model))\n",
    "trainer.extend(extensions.LogReport())\n",
    "trainer.extend(extensions.PrintReport(['epoch', 'main/accuracy', 'validation/main/accuracy']))\n",
    "trainer.extend(extensions.ProgressBar())\n",
    "\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix: MLP\n",
    "単純な3layers MLPで95%くらい出るよ！\n",
    "CNNで99%を目指そう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP(Chain):\n",
    "    def __init__(self, n_units, n_out):\n",
    "        super(MLP, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(None, n_units)\n",
    "            self.l2 = L.Linear(None, n_units)\n",
    "            self.l3 = L.Linear(None, n_out)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        y = self.l3(h2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = L.Classifier(MLP(100, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" LeNet5 \"\"\"\n",
    "class LeNet5(Chain):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv1 = L.Convolution2D(\n",
    "                in_channels=1, out_channels=6, ksize=5, stride=1)\n",
    "            self.conv2 = L.Convolution2D(\n",
    "                in_channels=6, out_channels=16, ksize=5, stride=1)\n",
    "            self.conv3 = L.Convolution2D(\n",
    "                in_channels=16, out_channels=120, ksize=4, stride=1)\n",
    "            self.fc4 = L.Linear(None, 84)\n",
    "            self.fc5 = L.Linear(84, 10)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.sigmoid(self.conv1(x))\n",
    "        h = F.max_pooling_2d(h, 2, 2)\n",
    "        h = F.sigmoid(self.conv2(h))\n",
    "        h = F.max_pooling_2d(h, 2, 2)\n",
    "        h = F.sigmoid(self.conv3(h))\n",
    "        h = F.sigmoid(self.fc4(h))\n",
    "        return self.fc5(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課題2 Data Augmentation\n",
    "Data Augmentationを実際にやってみましょう。\n",
    "\n",
    "numpyの行列操作やscipy, scikit-imageなどのメソッドを駆使して画像をいじります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lena = imread('./lena_color.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(lena)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal flippingの実装\n",
    "目標：\n",
    "<img src=\"images/lena_horizontal_flipped.png\" width=\"200\"/>\n",
    "\n",
    "行列のスライス\n",
    "\n",
    "ヒント(?)1\n",
    "```python\n",
    "x = np.array([1, 2, 3])\n",
    "x[::-1]  # array([3, 2, 1])\n",
    "```\n",
    "\n",
    "ヒント(?)2\n",
    "```python\n",
    "x = np.array([\n",
    "  [1, 2, 3],\n",
    "  [4, 5, 6],\n",
    "  [7, 8, 9],\n",
    "])\n",
    "x[:, 1]  # array([2, 5, 8])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lena_hf = lena[:, ::-1, :]\n",
    "plt.imshow(lena_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.io import imsave\n",
    "\n",
    "imsave('./images/lena_horizontal_flipped.png', lena_hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale augmentation\n",
    "目標(例:1.2倍)：\n",
    "<img src=\"./images/lena_zoom120.png\" width=\"200\"/>\n",
    "\n",
    "scipy.misc.imresize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imresize\n",
    "\n",
    "resized_lena = imresize(lena, 1.2)\n",
    "org_h, org_w = lena.shape[0:2]\n",
    "h, w = resized_lena.shape[0:2]\n",
    "sx = (w - org_w) // 2\n",
    "sy = (h - org_h) // 2\n",
    "\n",
    "resized_lena = resized_lena[sy:sy+org_h, sx:sx+org_w, :]\n",
    "plt.imshow(resized_lena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imsave('./images/lena_zoom120.png', resized_lena)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random crop\n",
    "目標（例）:\n",
    "\n",
    "<img src=\"./images/lena_cropped_0.png\" width=\"200\"/>\n",
    "<img src=\"./images/lena_cropped_1.png\" width=\"200\"/>\n",
    "<img src=\"./images/lena_cropped_2.png\" width=\"200\"/>\n",
    "<img src=\"./images/lena_cropped_3.png\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_lena = imresize(lena, 1.5)\n",
    "for i in range(4):\n",
    "    sx = np.random.randint(0, w-org_w)\n",
    "    sy = np.random.randint(0, h-org_h)\n",
    "    cropped_lena = resized_lena[sy:sy+org_h, sx:sx+org_w, :]\n",
    "    plt.imshow(cropped_lena)\n",
    "    imsave('./images/lena_cropped_{}.png'.format(i), cropped_lena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
