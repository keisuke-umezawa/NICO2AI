# 第7回：畳み込みニューラルネットワーク (1)

## 到達目標
* 畳み込みニューラルネットワーク (CNN) が開発されるまでの歴史を概観する
* CNNを用いて画像分類タスクを実装・実行できる

## キーワード
* 単純型・複雑型細胞
* 畳み込み層
* プーリング層
* 全結合層
* 特徴マップ
* AlexNet

## 講師へのお願い
* 新出用語が多いので、1つ1つの用語を混同しないように教えてください
* 画像の取り扱いがやや煩雑なので、その入出力形式にも注意を払ってください

## タイムスケジュール
### 前回の復習 (5分)
### 講義・基礎演習 (85分)
#### Part 1. 視覚の計算モデルの歴史
##### 講義 (15分)
* 全結合NNの問題点 (パラメータ数の多さ、学習の不安定性、etc.)
* 局所結合ネットワーク
* 単純型細胞と複雑型細胞
* Fukushimaのネオコグニトロン
* LeNet
* AlexNet

#### Part 2. 畳み込みニューラルネットの基礎
##### 講義 (40分)
* 畳込みニューラルネット (CNN)
* 一般的なCNNの構成
* 畳み込み層
* パディング/ストライド
* プーリング層 (Max pooling/average pooling)
* チャネルと特徴マップ
* 局所反応正規化 (Local Response Normalization; LRN)
* 全結合層
* 畳み込み層の誤差逆伝播法

##### 基礎演習 (30分)
* 畳み込み層 (L.Convolution2D)
* パディング・ストライドの指定 (pad, stride)
* プーリング層 (F.max\_pooling, F.avg\_pooling)
* 画像の入力
* 小課題：畳み込み・プーリングを使ってみる (使い方の学習)
* 小課題：パラメータ数の計算と比較
* Variableの形状変換 (F.flatten())

### 実践演習 (85分)
#### 課題1: Chainerを用いたCNNの実装 (50分)
* MNISTデータセットを用いて、CNNの学習に挑戦
* 第6回までの知識と合わせて、正解率99%を目指そう
* 使えるツール：畳み込み層、プーリング層、Batch Normalization、SGD、Adam、Dropout

#### 課題2a：(パイロット用) Data Augmentation (20分)
* Horizontal flippingの実装 (行列のスライス)
* Scale augmentation (scipy.misc.imresize)
* Random crop/padding (np.pad)

#### 課題2b：(本番用) 未定 (20分)

#### 解説・コードレビュー (15分)
### フィードバック・次回予告 (5分)

## 参考文献 (講師の方も随時追加お願いします)
