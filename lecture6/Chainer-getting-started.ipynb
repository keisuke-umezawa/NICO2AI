{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第６回：Chainer入門\n",
    "\n",
    "## 到達目標\n",
    "* Chainerを使って全結合のニューラルネットを記述し、実行することができる\n",
    "* ニューラルネットとその他の手法との関係性とその特性の差を理解する\n",
    "* ニューラルネットの基本的な学習テクニックを学ぶ\n",
    "\n",
    "## キーワード\n",
    "* Chainer\n",
    "* Define-by-Run\n",
    "* Link, Chain, Optimizer\n",
    "\n",
    "## タイムスケジュール\n",
    "### 前回の復習 (5分)\n",
    "### 講義・基礎演習 (85分)\n",
    "#### Part 1. Chainer入門 (50分)\n",
    "##### 講義 (10分)\n",
    "* Chainerとは\n",
    "* \"Define-and-Run\"と\"Define-by-Run\"\n",
    "* Chainerの特長と他フレームワークとの比較\n",
    "* 計算グラフの記述\n",
    "* (GPUへの対応)\n",
    "##### 基礎演習 (40分)\n",
    "* Variable\n",
    "* 自動微分\n",
    "* Link\n",
    "* Chain\n",
    "* L.Linear, F.relu, F.softmax\\_cross\\_entropy\n",
    "* 多層パーセプトロンのChainerによる記述\n",
    "* Optimizer\n",
    "* (Trainerを用いない)ニューラルネットの学習\n",
    "* モデルの保存と読み込み (Serializer)\n",
    "* (Trainer/Updater)\n",
    "* (datasets/iterators)\n",
    "* (Extension(Evaluator, LogReport, PrintReport, ProgressBar, snapshot))\n",
    "* (Trainerを用いた)ニューラルネットの学習\n",
    "* (GPU対応コードの実装)\n",
    "* 課題:Chainerを用いたロジスティック回帰の実装\n",
    "\n",
    "#### Part 2. ニューラルネットの学習テクニック (15分)\n",
    "* NNの最適化手法(Momentum法(MomentumSGD)/AdaGrad/Adam)\n",
    "* NNの正則化手法(Dropout)\n",
    "* 勾配消失問題\n",
    "* Heの初期化\n",
    "* Batch Normalization\n",
    "\n",
    "#### Part 3. 他手法との比較 (20分)\n",
    "* 汎化誤差・交差検証 (復習)\n",
    "* 機械学習モデルの性能を決める要素 (特徴選択・前処理・線形性)\n",
    "* SVMとNNの比較\n",
    "* モデル選択\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chainerとは？\n",
    "\n",
    "## 日本製のディープラーニングフレームワーク\n",
    "\n",
    "<img src=\"./images/01.png\" width=\"400\" />\n",
    "\n",
    "**Chainer**は日本の企業である**Preferred Networks**社が開発をすすめるディープラーニング（ニューラルネットワーク）に特化したPythonで使用できるフレームワークです。\n",
    "他にも、Googleが提供するTensorFlowやそのラッパーのKerasもあり、個人的には日本ではこのどちらかを使っている人が多いかなと感じます。\n",
    "\n",
    "**Chainerはもともと習得が簡単なインターフェースで作られている面**と、他のフレームワークに比べて、ディープラーニングの開発を論文レベルだったりの**カスタマイズをする際に非常に柔軟に対応できる**といった点が魅力に感じています。\n",
    "\n",
    "## 特徴は「Define by Run」\n",
    "**Define by Run**と呼ばれる仕組みがGoogleのTensorFlowをはじめとした他のフレームワークとの大きな違いであり、初心者にとっては、**学習途中に数値やサイズの確認が出来るといったデバックの容易さ**がメリットです（Chainerの開発者から直接聞きました）。  \n",
    "たしかに、**学習途中にどのような挙動をしているか、どこでエラーが起きているか**は開発者にとっては非常に大事なため、この構造を採用しているのは、大きなメリットだと感じます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chainerでわからないことがあれば、開発者にSlackで聞こう！\n",
    "\n",
    "ChainerではPFNの開発者にダイレクトに質問できるSlackがあり、セミナー参加者は正体大歓迎とPFNの方も言ってくださっているので、ぜひ[こちら](https://docs.google.com/forms/d/e/1FAIpQLSfqL9XjnqZUIwLOz4K9Oxm8-Ce246IRP51-vZa7HOrofJT9rA/viewform)からメールアドレスを登録して、Slackに招待してもらいましょう。  \n",
    "[**▶ Chainer Slack 受付フォーム**](https://docs.google.com/forms/d/e/1FAIpQLSfqL9XjnqZUIwLOz4K9Oxm8-Ce246IRP51-vZa7HOrofJT9rA/viewform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算グラフの記述\n",
    "まずは、３ノードの入力層と２ノードの出力層の部分を表現していきましょう。\n",
    "\n",
    "<img src=\"./images/02.png\" width=\"400\" />\n",
    "\n",
    "ノードの結合を表す時は、chainer.linksを使用します。\n",
    "そして、このchainer.linksをLとして宣言するので、覚えておきましょう（公式リファレンス推奨の方法）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chainer.links as L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 -> 2 のリンクをl1として、以下のように宣言します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1 = L.Linear(3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これだけで完了です。\n",
    "L.Linearの意味は、みなさんが勉強されてた重回帰分析の線形結合という意味です。\n",
    "\n",
    "そして、宣言したリンクの重み（W）とバイアス（b）はランダムに初期化されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable W([[ 0.32169408, -0.9133054 , -1.17567265],\n",
       "            [ 0.44504353,  0.70877433, -0.44179112]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable b([ 0.,  0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このランダムに初期化されたパラメータを最適化の初期値に使用します。\n",
    "\n",
    "Chainerの中で必要な基礎はこのリンクの書き方を抑えておけば、一旦OKです。\n",
    "他にも色々な機能がありますが、これは次の実践的な非線形回帰を試しながら、見ていきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chainerでワインのクラス分類を行おう\n",
    "実際の問題を想定しながら、Chainerの使い方を見ていきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルを定義しよう\n",
    "\n",
    "<img src=\"./images/03.png\" width=\"400\" />\n",
    "\n",
    "Chainerでは、まずモデルの定義を行います。\n",
    "今回は下記のような、４層のニューラルネットワーク（NN）の作り方を学びましょう。\n",
    "\n",
    "まず、Chainerのモデルの中で使用するchainer.functionsを読み込んでおきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chainer.fuinctionsでは、F.reluとして**Relu関数**や、F.mean_squared_errorとして**平均二乗誤差（Mean Squared Errors）**、F.softmax_cross_entropyとして**ソフトマックスクロスエントロピー**の計算など、ニューラルネットワークでよく使用する関数が定義されています。\n",
    "\n",
    "そして、今回の４層のモデルをChainerでは以下のように書きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MLP: Multi-layer Perceptron\n",
    "class MLP(chainer.Chain):\n",
    "    \n",
    "    def __init__(self, n_units1, n_units2, n_output):\n",
    "        super().__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(None, n_units1)\n",
    "            self.l2 = L.Linear(None, n_units2)\n",
    "            self.l3 = L.Linear(None, n_output)\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        return self.l3(h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "少し多いため戸惑いますが、基本的には雛形に分類の問題はカスタマイズするだけで実装できるため、カスタマイズするポイントを覚えておきましょう。\n",
    "\n",
    "- `__init__`：モデルの構造を宣言\n",
    "- `__call__`：評価関数を宣言\n",
    "\n",
    "他にも書き方（この自由度の高さがChainerの魅力の１つ）がありますが、簡単なモデルの場合はこのような構造で書いておくことをおすすめします。\n",
    "\n",
    "`__init__`内にモデルの構造を書き、`__call__`内でそれをつなぎ合わせるイメージです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chainerでは定義するモデルとClassifierを繋げて使う\n",
    "これは、Chainer流の書き方に合わせるためですが、基本的には、Chainerの分類を書く際には、以下の２つのモデルに分けることが多いです。\n",
    "\n",
    "- 順伝播で予測値を計算（推論）を行うモデル　←　今回のMLP\n",
    "- 予測値から評価関数を計算するモデル　←　この後のL.Classifier\n",
    "\n",
    "この書き方は絶対というわけではありませんが、この書き方を覚えておくと、リファレンスを見た際の対応関係がわかりやすいため、おすすめです。\n",
    "\n",
    "評価関数を計算する部分である L.Classifier は既にChainer側で準備されており、その中でSoftmax関数に変換して計算を行ってくれます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル宣言の際の注意\n",
    "\n",
    "また、モデルの宣言の前に気をつけないといけないことがあります。\n",
    "\n",
    "Chainerのchainer.linksで宣言したL.Lienarの中では宣言したタイミングで、重みWやバイアスbがランダムに初期化されていました。\n",
    "そのため、実行毎に結果が異なってしまい、「昨日うまくいったのに、全く同じプログラムでも今日はうまくいかない」といったことがあり得ます。\n",
    "\n",
    "この対策として、**乱数のシード**を固定することがあります。\n",
    "乱数のシードを固定しておくと、毎回同じ結果が得られ、**再現性の確保**ができます。\n",
    "\n",
    "**これはデータ解析の際には非常に重要なため、絶対に忘れないようにしましょう。**\n",
    "\n",
    "Chainerが使用する乱数のシードはPython標準のrandomではなく、Numpyの中で使用されているnumpy.randomであるため、お気をつけください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "つぎに、Numpyの乱数のシードを固定しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# シードの固定\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そして、モデルを実際に使っていく際には、下記のように宣言をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NNモデルに必要なパラメータの設定\n",
    "n_units1 = 10\n",
    "n_units2 = 10\n",
    "n_output = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NNモデルの宣言\n",
    "mlp = MLP(n_units1, n_units2, n_output)\n",
    "\n",
    "# 分類用にラップ\n",
    "model = L.Classifier(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NNモデルの中で、ノードの数を直に書いて宣言しても良いのですが、こちらのように、ノードの数を**引数**としておくことで、柔軟に変更できるため、こちらの書き方がおすすめです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizerを定義しよう\n",
    "\n",
    "Chainerではoptimizerと呼ばれる最適化を担当する部分のモジュールがあります。\n",
    "最適化とは**最急降下法**、**確率的勾配法（SGD)**などのアルゴリズムのことです。\n",
    "\n",
    "optimizerはchainer.optimizersにあるため、こちらを読み込みましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chainer import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 最適化のアルゴリズムには SGD を使用\n",
    "optimizer = optimizers.SGD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定義したoptimizerと作成したmodelを紐付けるために、optimizer.setup(model)が必要となるため、忘れないようにしましょう。\n",
    "\n",
    "一番シンプルな場合は、このモデルの宣言とoptimizerの宣言で完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer.setup(model)  # modelと紐付ける"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データを準備しよう\n",
    "\n",
    "<img src=\"./images/04.png\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSVファイルからの読み込み\n",
    "\n",
    "**CSVファイル**とは聞き慣れている方も多いかと思いますが、データが**カンマ区切り**で表現されているデータのことです。\n",
    "\n",
    "**wine_class.csv**のファイルを準備しているので、こちらを読み込んでみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandasで読み込み\n",
    "CSVファイル含め、データの読み込みには**Pandas**と呼ばれる外部モジュールを使用すると便利です。\n",
    "整理をしておくと、データ解析の基礎となる３つのツールの位置づけはこちらです。\n",
    "\n",
    "- Numpy：数値データの取り扱い（線形代数含め）\n",
    "- Pandas：データベースの操作（小規模のCSVファイル含め）\n",
    "- Matplotlib：プロット\n",
    "\n",
    "特に、PandasはJupyter Notebookとの相性も良く、綺麗に表を表示することができるため、おすすめです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、Pandasを読み込みましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ローカルのファイルから読み込む\n",
    "df = pd.read_csv('wine_class.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**df** は **data frame** の略であり、pandasの例でよく出てくる名前ですので、覚えておきましょう。\n",
    "\n",
    "Pandasで読み込んだデータはdfで内容を確認でき、df.head()と実行すると、先頭の5つが表示され、長すぎないのでおすすめです。\n",
    "なお、df.head(10)とすると、先頭の10個が表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>14.20</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "      <td>112</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>14.39</td>\n",
       "      <td>2.45</td>\n",
       "      <td>14.6</td>\n",
       "      <td>96</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>14.06</td>\n",
       "      <td>2.61</td>\n",
       "      <td>17.6</td>\n",
       "      <td>121</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.31</td>\n",
       "      <td>5.05</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>14.83</td>\n",
       "      <td>2.17</td>\n",
       "      <td>14.0</td>\n",
       "      <td>97</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.29</td>\n",
       "      <td>5.20</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>13.86</td>\n",
       "      <td>2.27</td>\n",
       "      <td>16.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.22</td>\n",
       "      <td>7.22</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "0      1    14.23  2.43               15.6        127           2.80   \n",
       "1      1    13.20  2.14               11.2        100           2.65   \n",
       "2      1    13.16  2.67               18.6        101           2.80   \n",
       "3      1    14.37  2.50               16.8        113           3.85   \n",
       "4      1    13.24  2.87               21.0        118           2.80   \n",
       "5      1    14.20  2.45               15.2        112           3.27   \n",
       "6      1    14.39  2.45               14.6         96           2.50   \n",
       "7      1    14.06  2.61               17.6        121           2.60   \n",
       "8      1    14.83  2.17               14.0         97           2.80   \n",
       "9      1    13.86  2.27               16.0         98           2.98   \n",
       "\n",
       "   Flavanoids  Nonflavanoid phenols  Color intensity   Hue  Proline  \n",
       "0        3.06                  0.28             5.64  1.04     1065  \n",
       "1        2.76                  0.26             4.38  1.05     1050  \n",
       "2        3.24                  0.30             5.68  1.03     1185  \n",
       "3        3.49                  0.24             7.80  0.86     1480  \n",
       "4        2.69                  0.39             4.32  1.04      735  \n",
       "5        3.39                  0.34             6.75  1.05     1450  \n",
       "6        2.52                  0.30             5.25  1.02     1290  \n",
       "7        2.51                  0.31             5.05  1.06     1295  \n",
       "8        2.98                  0.29             5.20  1.08     1045  \n",
       "9        3.15                  0.22             7.22  1.01     1045  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各カラムを抽出する場合は、辞書型のようにカラム名を指定すればOKです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "5    1\n",
       "6    1\n",
       "7    1\n",
       "8    1\n",
       "9    1\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、.valuesと付けると、Pandasの形式からNumpyの形式に変換でき、これをよく用います。\n",
    "理由として、ChainerやScikit-learnのライブラリでは、Numpyの形式で保存された変数を前提に設計されていることが多いため、データの抽出が終わった最後に、.valuesを付けてNumpyの形式に変換しておくと無難です"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、入力変数が多い場合など、手動でカラム名を全部指定することが面倒なときは、df.ilocを使用すると、Numpy含めた行列の表現として抽出することができます。\n",
    "\n",
    "例えば、全ての行（:）で１〜２列目（0:2）を抽出したい場合は以下のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>14.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>14.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>14.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>14.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>13.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol\n",
       "0      1    14.23\n",
       "1      1    13.20\n",
       "2      1    13.16\n",
       "3      1    14.37\n",
       "4      1    13.24\n",
       "5      1    14.20\n",
       "6      1    14.39\n",
       "7      1    14.06\n",
       "8      1    14.83\n",
       "9      1    13.86"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, 0:2].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力変数と出力変数に分ける"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はワインの成分から等級を分類するといった問題設定であるため、\n",
    "\n",
    "- 入力変数：AlcoholからProlineまでの数値データ\n",
    "- 出力変数：Class\n",
    "\n",
    "を採用します。\n",
    "\n",
    "先ほど紹介したdf.ilocを使用してデータを切り分けましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_x = df.iloc[:, 1:].values\n",
    "_t = df.iloc[:, 0].values - 1  # chainerのラベル付けは0スタートのため、等級は1からではなく、0から始めておく"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、Chainerで使用する際には、\n",
    "\n",
    "- 実数値：np.float32\n",
    "- 整数値：np.int32\n",
    "\n",
    "に変換しておかないとよくエラーがでるため、事前にこちらへ変換しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array(_x, dtype=np.float32)\n",
    "t = np.array(_t, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※ 一時的に保存する変数名に_xのようにアンダーバー（アンダースコア）を付けています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variableに変換\n",
    "Chainerを使う時になかなか難しいのが変数の取り扱いです。  \n",
    "Chainerでは、chainer.Variableで定義されている変数の方に変換してから、モデルの学習用に使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chainer import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chainer用の変数として宣言\n",
    "x_ch = Variable(x)\n",
    "t_ch = Variable(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルを学習させよう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデル学習の流れは以下のとおりです。\n",
    "\n",
    "> 順伝播の計算　▶　勾配の計算　▶　パラメータの調整\n",
    "\n",
    "これをforでループさせ、評価関数の値が小さくなるように、パラメータをどんどん調整していきます。\n",
    "\n",
    "それでは、学習ループのプログラムを書いていきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1000回順伝播と逆伝播を繰り返す\n",
    "for i in range(1000):\n",
    "    \n",
    "    # 勾配情報の初期化（chainerの仕様）\n",
    "    model.cleargrads()\n",
    "    \n",
    "    # 順伝播（評価関数の計算）\n",
    "    loss = model(x_ch, t_ch)\n",
    "    \n",
    "    # 勾配（傾き）の計算 <-　誤差逆伝播法が使用されている\n",
    "    loss.backward()\n",
    "    \n",
    "    # パラメータの調整\n",
    "    optimizer.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本的には最初に提示した流れをforで所定回数繰り返しています。\n",
    "\n",
    "唯一、model.cleargrad()という項があり、これはChainerの仕様なのですが、学習の前に勾配を保存している変数を初期化する必要があります。\n",
    "ただ、こちらは「Chainerの仕様」であるため、特に気にせず、毎回書くものだと思っておいてください。\n",
    "\n",
    "loss = model(x_ch, t_ch)の項では、modelを関数風に呼び出しているため、modelの`__call__`の関数が呼び出されており、評価関数の値が計算されています。\n",
    "\n",
    "そして、その計算した評価関数をもとに、loss.backward()とすると、不思議ですが、model内のパラメータWとbの勾配に関するアトリビュートであるmodel.W.gradや model.b.gradに最新の勾配の値が代入されるようになっています。\n",
    "このあたりは「なぜ？」というよりも「Chainerの仕様だから」と片付けてしまう方が良いと思います。\n",
    "最初に説明した**Define by Run**を実現するための構造であったりします。\n",
    "\n",
    "また、上記の学習のプログラムでは、学習の経過の様子がわからないため、lossを保存するリストを準備してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = []  # 追記：訓練結果保存用のリスト\n",
    "for i in range(1000):\n",
    "    model.cleargrads()\n",
    "    loss = model(x_ch, t_ch)\n",
    "    loss.backward()\n",
    "    optimizer.update()\n",
    "    # 追記：プロットするように保存しておく\n",
    "    losses.append(loss.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで学習した結果を保存できるため、どれくらい評価関数の値（平均二乗誤差）が下がっているかプロットして確認しましょう。\n",
    "\n",
    "プロットには**Matplotlib**を使いましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEDCAYAAAAWUyJmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111432e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 評価関数の値をプロット\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果を確認しよう\n",
    "それでは、まだ学習させることで良くなりそうですが、現状のモデルに対して、どの程度うまくいっているかを目視で確認してみましょう。\n",
    "目視では、定量的な厳密性のある議論ができませんが、そもそも全くうまくいっていないことは瞬時に判断することができるため、最初は目視による確認から入ることがおすすめです。\n",
    "\n",
    "まず、現状のモデルで予測値の計算（推論）を行いましょう。  \n",
    "※ まず１番目のデータに対する計算です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = mlp(x_ch[None, 0]).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちなみに、mlp(x[0])と書かずに、mlp(x[None, 0])と書くことに違和感があると思いますが、Chainerでは一行目にバッチサイズが来ないといけないため、こちらを変換する必要があります。\n",
    "こちらを変更するための書き方は下記のように複数あります。\n",
    "\n",
    "- x[None, 0]\n",
    "- x[0].reshape(1, len(x[0]))\n",
    "- np.array([x[0]])\n",
    "\n",
    "一番シンプルな書き方がx[None, 0]であるため、こちらを使用することをおすすめします。\n",
    "※ PFNの方もこちらの書き方でした。\n",
    "\n",
    "ここで、Chainerで定義したmodelから得られる計算の値はChainerのVariableで得られるため、数値として取り扱うために.dataでnumpyの形式で数値を取り出しています。\n",
    "\n",
    "推論した結果は以下のとおりです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00681615,  0.19196831, -0.1987845 ]], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こちらのように、クラスの予測値が出てきてくれるわけではなく、回帰の結果が出力されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = F.softmax(y).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3313936 ,  0.39879954,  0.2698068 ]], dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こちらのように、softmax関数にかけた後に、np.argmaxで確率が最大のインデックスが取得でき、こちらが該当するクラスになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainerを使おう\n",
    "\n",
    "<img src=\"./images/05.png\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainerとは？\n",
    "先ほどの講義では、実際にカスタマイズすべき点の挙動も確認しながら、Chainerの使い方を見てきましたが、この方法では実務に入る際に問題点があります。\n",
    "\n",
    "- バッチサイズの指定を学習ループのfor文にいちいち書かないといけない（結構めんどくさい）\n",
    "- 検証用データに対する結果を計算するために、追記しないといけない（結構めんどくさい）\n",
    "- ループしている状況を可視化して確認したい際には print などでいちいち確認するためのコードを書かないといけない（これが入るとコードの本質を見失う）\n",
    "- 訓練データと検証データで時系列的にどの程度誤差が下がっているか確認するためのコードも書かないといけない（これを見ないと、オーバーフィッティングに気づけないため必須）\n",
    "- etc…\n",
    "\n",
    "といったように、先ほどまでの手順で使えるようになるのと、実用化を視野に入れるのでは、結構なレベルの差が合ったりします。\n",
    "\n",
    "この部分をサポートしてくれているのがChainerのTrainerです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 乱数のシードを固定 (再現性の確保)\n",
    "np.random.seed(1)\n",
    "\n",
    "# モデルの宣言\n",
    "n_units1, n_units2, n_output = 10, 10, 3\n",
    "mlp = MLP(n_units1, n_units2, n_output)\n",
    "model = L.Classifier(mlp)\n",
    "\n",
    "# optimizerの設定\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasetの設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainerを使用する際は、Variableにデータを変換するといった手順は省略できます。\n",
    "その代わり、データを所定の形式に変換しておく必要があります。\n",
    "\n",
    "メモリに乗り切る程度の小規模なデータの際は、**入力変数と教師データをタプルで１セット**にして、それを**リスト化**しておくことがChainer推奨の方法だそうです。\n",
    "\n",
    "<img src=\"./images/06.png\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = list(zip(x, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こちらのように、zip(x, t)で入力変数と教師データをタプル化した後、それをlistでリスト化します。\n",
    "こちらは毎回同じ記述であるため、このように書くと覚えておいていただければOKです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([  1.42299995e+01,   2.43000007e+00,   1.56000004e+01,\n",
       "           1.27000000e+02,   2.79999995e+00,   3.05999994e+00,\n",
       "           2.80000001e-01,   5.63999987e+00,   1.03999996e+00,\n",
       "           1.06500000e+03], dtype=float32), 0),\n",
       " (array([  1.31999998e+01,   2.14000010e+00,   1.11999998e+01,\n",
       "           1.00000000e+02,   2.65000010e+00,   2.75999999e+00,\n",
       "           2.59999990e-01,   4.38000011e+00,   1.04999995e+00,\n",
       "           1.05000000e+03], dtype=float32), 0),\n",
       " (array([  1.31599998e+01,   2.67000008e+00,   1.86000004e+01,\n",
       "           1.01000000e+02,   2.79999995e+00,   3.24000001e+00,\n",
       "           3.00000012e-01,   5.67999983e+00,   1.02999997e+00,\n",
       "           1.18500000e+03], dtype=float32), 0),\n",
       " (array([  1.43699999e+01,   2.50000000e+00,   1.67999992e+01,\n",
       "           1.13000000e+02,   3.84999990e+00,   3.49000001e+00,\n",
       "           2.39999995e-01,   7.80000019e+00,   8.60000014e-01,\n",
       "           1.48000000e+03], dtype=float32), 0),\n",
       " (array([  1.32399998e+01,   2.86999989e+00,   2.10000000e+01,\n",
       "           1.18000000e+02,   2.79999995e+00,   2.69000006e+00,\n",
       "           3.89999986e-01,   4.32000017e+00,   1.03999996e+00,\n",
       "           7.35000000e+02], dtype=float32), 0),\n",
       " (array([  1.41999998e+01,   2.45000005e+00,   1.51999998e+01,\n",
       "           1.12000000e+02,   3.26999998e+00,   3.39000010e+00,\n",
       "           3.40000004e-01,   6.75000000e+00,   1.04999995e+00,\n",
       "           1.45000000e+03], dtype=float32), 0),\n",
       " (array([  1.43900003e+01,   2.45000005e+00,   1.46000004e+01,\n",
       "           9.60000000e+01,   2.50000000e+00,   2.51999998e+00,\n",
       "           3.00000012e-01,   5.25000000e+00,   1.01999998e+00,\n",
       "           1.29000000e+03], dtype=float32), 0),\n",
       " (array([  1.40600004e+01,   2.60999990e+00,   1.76000004e+01,\n",
       "           1.21000000e+02,   2.59999990e+00,   2.50999999e+00,\n",
       "           3.10000002e-01,   5.05000019e+00,   1.05999994e+00,\n",
       "           1.29500000e+03], dtype=float32), 0),\n",
       " (array([  1.48299999e+01,   2.17000008e+00,   1.40000000e+01,\n",
       "           9.70000000e+01,   2.79999995e+00,   2.98000002e+00,\n",
       "           2.89999992e-01,   5.19999981e+00,   1.08000004e+00,\n",
       "           1.04500000e+03], dtype=float32), 0),\n",
       " (array([  1.38599997e+01,   2.26999998e+00,   1.60000000e+01,\n",
       "           9.80000000e+01,   2.98000002e+00,   3.15000010e+00,\n",
       "           2.19999999e-01,   7.21999979e+00,   1.00999999e+00,\n",
       "           1.04500000e+03], dtype=float32), 0),\n",
       " (array([  1.41000004e+01,   2.29999995e+00,   1.80000000e+01,\n",
       "           1.05000000e+02,   2.95000005e+00,   3.31999993e+00,\n",
       "           2.19999999e-01,   5.75000000e+00,   1.25000000e+00,\n",
       "           1.51000000e+03], dtype=float32), 0),\n",
       " (array([  1.41199999e+01,   2.31999993e+00,   1.67999992e+01,\n",
       "           9.50000000e+01,   2.20000005e+00,   2.43000007e+00,\n",
       "           2.59999990e-01,   5.00000000e+00,   1.16999996e+00,\n",
       "           1.28000000e+03], dtype=float32), 0),\n",
       " (array([  1.37500000e+01,   2.41000009e+00,   1.60000000e+01,\n",
       "           8.90000000e+01,   2.59999990e+00,   2.75999999e+00,\n",
       "           2.89999992e-01,   5.59999990e+00,   1.14999998e+00,\n",
       "           1.32000000e+03], dtype=float32), 0),\n",
       " (array([  1.47500000e+01,   2.39000010e+00,   1.13999996e+01,\n",
       "           9.10000000e+01,   3.09999990e+00,   3.69000006e+00,\n",
       "           4.30000007e-01,   5.40000010e+00,   1.25000000e+00,\n",
       "           1.15000000e+03], dtype=float32), 0),\n",
       " (array([  1.43800001e+01,   2.38000011e+00,   1.20000000e+01,\n",
       "           1.02000000e+02,   3.29999995e+00,   3.64000010e+00,\n",
       "           2.89999992e-01,   7.50000000e+00,   1.20000005e+00,\n",
       "           1.54700000e+03], dtype=float32), 0),\n",
       " (array([  1.36300001e+01,   2.70000005e+00,   1.72000008e+01,\n",
       "           1.12000000e+02,   2.84999990e+00,   2.91000009e+00,\n",
       "           3.00000012e-01,   7.30000019e+00,   1.27999997e+00,\n",
       "           1.31000000e+03], dtype=float32), 0),\n",
       " (array([  1.43000002e+01,   2.72000003e+00,   2.00000000e+01,\n",
       "           1.20000000e+02,   2.79999995e+00,   3.14000010e+00,\n",
       "           3.30000013e-01,   6.19999981e+00,   1.07000005e+00,\n",
       "           1.28000000e+03], dtype=float32), 0),\n",
       " (array([  1.38299999e+01,   2.61999989e+00,   2.00000000e+01,\n",
       "           1.15000000e+02,   2.95000005e+00,   3.40000010e+00,\n",
       "           4.00000006e-01,   6.59999990e+00,   1.13000000e+00,\n",
       "           1.13000000e+03], dtype=float32), 0),\n",
       " (array([  1.41899996e+01,   2.48000002e+00,   1.65000000e+01,\n",
       "           1.08000000e+02,   3.29999995e+00,   3.93000007e+00,\n",
       "           3.19999993e-01,   8.69999981e+00,   1.23000002e+00,\n",
       "           1.68000000e+03], dtype=float32), 0),\n",
       " (array([  1.36400003e+01,   2.55999994e+00,   1.51999998e+01,\n",
       "           1.16000000e+02,   2.70000005e+00,   3.02999997e+00,\n",
       "           1.70000002e-01,   5.09999990e+00,   9.59999979e-01,\n",
       "           8.45000000e+02], dtype=float32), 0),\n",
       " (array([  1.40600004e+01,   2.27999997e+00,   1.60000000e+01,\n",
       "           1.26000000e+02,   3.00000000e+00,   3.17000008e+00,\n",
       "           2.39999995e-01,   5.65000010e+00,   1.09000003e+00,\n",
       "           7.80000000e+02], dtype=float32), 0),\n",
       " (array([  1.29300003e+01,   2.65000010e+00,   1.86000004e+01,\n",
       "           1.02000000e+02,   2.41000009e+00,   2.41000009e+00,\n",
       "           2.50000000e-01,   4.50000000e+00,   1.02999997e+00,\n",
       "           7.70000000e+02], dtype=float32), 0),\n",
       " (array([  1.37100000e+01,   2.35999990e+00,   1.66000004e+01,\n",
       "           1.01000000e+02,   2.60999990e+00,   2.88000011e+00,\n",
       "           2.70000011e-01,   3.79999995e+00,   1.11000001e+00,\n",
       "           1.03500000e+03], dtype=float32), 0),\n",
       " (array([  1.28500004e+01,   2.51999998e+00,   1.77999992e+01,\n",
       "           9.50000000e+01,   2.48000002e+00,   2.36999989e+00,\n",
       "           2.59999990e-01,   3.93000007e+00,   1.09000003e+00,\n",
       "           1.01500000e+03], dtype=float32), 0),\n",
       " (array([  1.35000000e+01,   2.60999990e+00,   2.00000000e+01,\n",
       "           9.60000000e+01,   2.52999997e+00,   2.60999990e+00,\n",
       "           2.80000001e-01,   3.51999998e+00,   1.12000000e+00,\n",
       "           8.45000000e+02], dtype=float32), 0),\n",
       " (array([  1.30500002e+01,   3.22000003e+00,   2.50000000e+01,\n",
       "           1.24000000e+02,   2.63000011e+00,   2.68000007e+00,\n",
       "           4.69999999e-01,   3.57999992e+00,   1.13000000e+00,\n",
       "           8.30000000e+02], dtype=float32), 0),\n",
       " (array([  1.33900003e+01,   2.61999989e+00,   1.61000004e+01,\n",
       "           9.30000000e+01,   2.84999990e+00,   2.94000006e+00,\n",
       "           3.40000004e-01,   4.80000019e+00,   9.20000017e-01,\n",
       "           1.19500000e+03], dtype=float32), 0),\n",
       " (array([  1.33000002e+01,   2.14000010e+00,   1.70000000e+01,\n",
       "           9.40000000e+01,   2.40000010e+00,   2.19000006e+00,\n",
       "           2.70000011e-01,   3.95000005e+00,   1.01999998e+00,\n",
       "           1.28500000e+03], dtype=float32), 0),\n",
       " (array([  1.38699999e+01,   2.79999995e+00,   1.93999996e+01,\n",
       "           1.07000000e+02,   2.95000005e+00,   2.97000003e+00,\n",
       "           3.70000005e-01,   4.50000000e+00,   1.25000000e+00,\n",
       "           9.15000000e+02], dtype=float32), 0),\n",
       " (array([  1.40200005e+01,   2.21000004e+00,   1.60000000e+01,\n",
       "           9.60000000e+01,   2.65000010e+00,   2.32999992e+00,\n",
       "           2.59999990e-01,   4.69999981e+00,   1.03999996e+00,\n",
       "           1.03500000e+03], dtype=float32), 0),\n",
       " (array([  1.37299995e+01,   2.70000005e+00,   2.25000000e+01,\n",
       "           1.01000000e+02,   3.00000000e+00,   3.25000000e+00,\n",
       "           2.89999992e-01,   5.69999981e+00,   1.19000006e+00,\n",
       "           1.28500000e+03], dtype=float32), 0),\n",
       " (array([  1.35799999e+01,   2.35999990e+00,   1.91000004e+01,\n",
       "           1.06000000e+02,   2.85999990e+00,   3.19000006e+00,\n",
       "           2.19999999e-01,   6.90000010e+00,   1.09000003e+00,\n",
       "           1.51500000e+03], dtype=float32), 0),\n",
       " (array([  1.36800003e+01,   2.35999990e+00,   1.72000008e+01,\n",
       "           1.04000000e+02,   2.42000008e+00,   2.69000006e+00,\n",
       "           4.19999987e-01,   3.83999991e+00,   1.23000002e+00,\n",
       "           9.90000000e+02], dtype=float32), 0),\n",
       " (array([  1.37600002e+01,   2.70000005e+00,   1.95000000e+01,\n",
       "           1.32000000e+02,   2.95000005e+00,   2.74000001e+00,\n",
       "           5.00000000e-01,   5.40000010e+00,   1.25000000e+00,\n",
       "           1.23500000e+03], dtype=float32), 0),\n",
       " (array([  1.35100002e+01,   2.65000010e+00,   1.90000000e+01,\n",
       "           1.10000000e+02,   2.34999990e+00,   2.52999997e+00,\n",
       "           2.89999992e-01,   4.19999981e+00,   1.10000002e+00,\n",
       "           1.09500000e+03], dtype=float32), 0),\n",
       " (array([  1.34799995e+01,   2.41000009e+00,   2.05000000e+01,\n",
       "           1.00000000e+02,   2.70000005e+00,   2.98000002e+00,\n",
       "           2.59999990e-01,   5.09999990e+00,   1.03999996e+00,\n",
       "           9.20000000e+02], dtype=float32), 0),\n",
       " (array([  1.32799997e+01,   2.83999991e+00,   1.55000000e+01,\n",
       "           1.10000000e+02,   2.59999990e+00,   2.68000007e+00,\n",
       "           3.40000004e-01,   4.59999990e+00,   1.09000003e+00,\n",
       "           8.80000000e+02], dtype=float32), 0),\n",
       " (array([  1.30500002e+01,   2.54999995e+00,   1.80000000e+01,\n",
       "           9.80000000e+01,   2.45000005e+00,   2.43000007e+00,\n",
       "           2.89999992e-01,   4.25000000e+00,   1.12000000e+00,\n",
       "           1.10500000e+03], dtype=float32), 0),\n",
       " (array([  1.30699997e+01,   2.09999990e+00,   1.55000000e+01,\n",
       "           9.80000000e+01,   2.40000010e+00,   2.64000010e+00,\n",
       "           2.80000001e-01,   3.70000005e+00,   1.17999995e+00,\n",
       "           1.02000000e+03], dtype=float32), 0),\n",
       " (array([  1.42200003e+01,   2.50999999e+00,   1.31999998e+01,\n",
       "           1.28000000e+02,   3.00000000e+00,   3.03999996e+00,\n",
       "           2.00000003e-01,   5.09999990e+00,   8.89999986e-01,\n",
       "           7.60000000e+02], dtype=float32), 0),\n",
       " (array([  1.35600004e+01,   2.30999994e+00,   1.62000008e+01,\n",
       "           1.17000000e+02,   3.15000010e+00,   3.28999996e+00,\n",
       "           3.40000004e-01,   6.13000011e+00,   9.49999988e-01,\n",
       "           7.95000000e+02], dtype=float32), 0),\n",
       " (array([  1.34099998e+01,   2.11999989e+00,   1.87999992e+01,\n",
       "           9.00000000e+01,   2.45000005e+00,   2.68000007e+00,\n",
       "           2.70000011e-01,   4.28000021e+00,   9.10000026e-01,\n",
       "           1.03500000e+03], dtype=float32), 0),\n",
       " (array([  1.38800001e+01,   2.58999991e+00,   1.50000000e+01,\n",
       "           1.01000000e+02,   3.25000000e+00,   3.55999994e+00,\n",
       "           1.70000002e-01,   5.42999983e+00,   8.79999995e-01,\n",
       "           1.09500000e+03], dtype=float32), 0),\n",
       " (array([  1.32399998e+01,   2.28999996e+00,   1.75000000e+01,\n",
       "           1.03000000e+02,   2.64000010e+00,   2.63000011e+00,\n",
       "           3.19999993e-01,   4.36000013e+00,   8.19999993e-01,\n",
       "           6.80000000e+02], dtype=float32), 0),\n",
       " (array([  1.30500002e+01,   2.09999990e+00,   1.70000000e+01,\n",
       "           1.07000000e+02,   3.00000000e+00,   3.00000000e+00,\n",
       "           2.80000001e-01,   5.03999996e+00,   8.79999995e-01,\n",
       "           8.85000000e+02], dtype=float32), 0),\n",
       " (array([  1.42100000e+01,   2.44000006e+00,   1.88999996e+01,\n",
       "           1.11000000e+02,   2.84999990e+00,   2.65000010e+00,\n",
       "           3.00000012e-01,   5.23999977e+00,   8.70000005e-01,\n",
       "           1.08000000e+03], dtype=float32), 0),\n",
       " (array([  1.43800001e+01,   2.27999997e+00,   1.60000000e+01,\n",
       "           1.02000000e+02,   3.25000000e+00,   3.17000008e+00,\n",
       "           2.70000011e-01,   4.90000010e+00,   1.03999996e+00,\n",
       "           1.06500000e+03], dtype=float32), 0),\n",
       " (array([  1.38999996e+01,   2.11999989e+00,   1.60000000e+01,\n",
       "           1.01000000e+02,   3.09999990e+00,   3.39000010e+00,\n",
       "           2.09999993e-01,   6.09999990e+00,   9.10000026e-01,\n",
       "           9.85000000e+02], dtype=float32), 0),\n",
       " (array([  1.41000004e+01,   2.40000010e+00,   1.87999992e+01,\n",
       "           1.03000000e+02,   2.75000000e+00,   2.92000008e+00,\n",
       "           3.19999993e-01,   6.19999981e+00,   1.07000005e+00,\n",
       "           1.06000000e+03], dtype=float32), 0),\n",
       " (array([  1.39399996e+01,   2.26999998e+00,   1.73999996e+01,\n",
       "           1.08000000e+02,   2.88000011e+00,   3.53999996e+00,\n",
       "           3.19999993e-01,   8.89999962e+00,   1.12000000e+00,\n",
       "           1.26000000e+03], dtype=float32), 0),\n",
       " (array([  1.30500002e+01,   2.03999996e+00,   1.23999996e+01,\n",
       "           9.20000000e+01,   2.72000003e+00,   3.26999998e+00,\n",
       "           1.70000002e-01,   7.19999981e+00,   1.12000000e+00,\n",
       "           1.15000000e+03], dtype=float32), 0),\n",
       " (array([  1.38299999e+01,   2.59999990e+00,   1.72000008e+01,\n",
       "           9.40000000e+01,   2.45000005e+00,   2.99000001e+00,\n",
       "           2.19999999e-01,   5.59999990e+00,   1.24000001e+00,\n",
       "           1.26500000e+03], dtype=float32), 0),\n",
       " (array([  1.38199997e+01,   2.42000008e+00,   1.40000000e+01,\n",
       "           1.11000000e+02,   3.88000011e+00,   3.74000001e+00,\n",
       "           3.19999993e-01,   7.05000019e+00,   1.00999999e+00,\n",
       "           1.19000000e+03], dtype=float32), 0),\n",
       " (array([  1.37700005e+01,   2.68000007e+00,   1.71000004e+01,\n",
       "           1.15000000e+02,   3.00000000e+00,   2.78999996e+00,\n",
       "           3.89999986e-01,   6.30000019e+00,   1.13000000e+00,\n",
       "           1.37500000e+03], dtype=float32), 0),\n",
       " (array([  1.37399998e+01,   2.25000000e+00,   1.63999996e+01,\n",
       "           1.18000000e+02,   2.59999990e+00,   2.90000010e+00,\n",
       "           2.09999993e-01,   5.84999990e+00,   9.20000017e-01,\n",
       "           1.06000000e+03], dtype=float32), 0),\n",
       " (array([  1.35600004e+01,   2.46000004e+00,   2.05000000e+01,\n",
       "           1.16000000e+02,   2.96000004e+00,   2.77999997e+00,\n",
       "           2.00000003e-01,   6.25000000e+00,   9.80000019e-01,\n",
       "           1.12000000e+03], dtype=float32), 0),\n",
       " (array([  1.42200003e+01,   2.29999995e+00,   1.62999992e+01,\n",
       "           1.18000000e+02,   3.20000005e+00,   3.00000000e+00,\n",
       "           2.59999990e-01,   6.38000011e+00,   9.39999998e-01,\n",
       "           9.70000000e+02], dtype=float32), 0),\n",
       " (array([  1.32900000e+01,   2.68000007e+00,   1.67999992e+01,\n",
       "           1.02000000e+02,   3.00000000e+00,   3.23000002e+00,\n",
       "           3.10000002e-01,   6.00000000e+00,   1.07000005e+00,\n",
       "           1.27000000e+03], dtype=float32), 0),\n",
       " (array([  1.37200003e+01,   2.50000000e+00,   1.67000008e+01,\n",
       "           1.08000000e+02,   3.40000010e+00,   3.67000008e+00,\n",
       "           1.89999998e-01,   6.80000019e+00,   8.89999986e-01,\n",
       "           1.28500000e+03], dtype=float32), 0),\n",
       " (array([  1.23699999e+01,   1.36000001e+00,   1.06000004e+01,\n",
       "           8.80000000e+01,   1.98000002e+00,   5.69999993e-01,\n",
       "           2.80000001e-01,   1.95000005e+00,   1.04999995e+00,\n",
       "           5.20000000e+02], dtype=float32), 1),\n",
       " (array([  1.23299999e+01,   2.27999997e+00,   1.60000000e+01,\n",
       "           1.01000000e+02,   2.04999995e+00,   1.09000003e+00,\n",
       "           6.29999995e-01,   3.26999998e+00,   1.25000000e+00,\n",
       "           6.80000000e+02], dtype=float32), 1),\n",
       " (array([  12.64000034,    2.01999998,   16.79999924,  100.        ,\n",
       "            2.01999998,    1.40999997,    0.52999997,    5.75      ,\n",
       "            0.98000002,  450.        ], dtype=float32), 1),\n",
       " (array([  1.36700001e+01,   1.91999996e+00,   1.80000000e+01,\n",
       "           9.40000000e+01,   2.09999990e+00,   1.78999996e+00,\n",
       "           3.19999993e-01,   3.79999995e+00,   1.23000002e+00,\n",
       "           6.30000000e+02], dtype=float32), 1),\n",
       " (array([  1.23699999e+01,   2.16000009e+00,   1.90000000e+01,\n",
       "           8.70000000e+01,   3.50000000e+00,   3.09999990e+00,\n",
       "           1.89999998e-01,   4.44999981e+00,   1.22000003e+00,\n",
       "           4.20000000e+02], dtype=float32), 1),\n",
       " (array([  12.17000008,    2.52999997,   19.        ,  104.        ,\n",
       "            1.88999999,    1.75      ,    0.44999999,    2.95000005,\n",
       "            1.45000005,  355.        ], dtype=float32), 1),\n",
       " (array([  1.23699999e+01,   2.55999994e+00,   1.81000004e+01,\n",
       "           9.80000000e+01,   2.42000008e+00,   2.65000010e+00,\n",
       "           3.70000005e-01,   4.59999990e+00,   1.19000006e+00,\n",
       "           6.78000000e+02], dtype=float32), 1),\n",
       " (array([  1.31099997e+01,   1.70000005e+00,   1.50000000e+01,\n",
       "           7.80000000e+01,   2.98000002e+00,   3.18000007e+00,\n",
       "           2.59999990e-01,   5.30000019e+00,   1.12000000e+00,\n",
       "           5.02000000e+02], dtype=float32), 1),\n",
       " (array([  1.23699999e+01,   1.91999996e+00,   1.96000004e+01,\n",
       "           7.80000000e+01,   2.10999990e+00,   2.00000000e+00,\n",
       "           2.70000011e-01,   4.67999983e+00,   1.12000000e+00,\n",
       "           5.10000000e+02], dtype=float32), 1),\n",
       " (array([  1.33400002e+01,   2.35999990e+00,   1.70000000e+01,\n",
       "           1.10000000e+02,   2.52999997e+00,   1.29999995e+00,\n",
       "           5.50000012e-01,   3.17000008e+00,   1.01999998e+00,\n",
       "           7.50000000e+02], dtype=float32), 1),\n",
       " (array([  1.22100000e+01,   1.75000000e+00,   1.67999992e+01,\n",
       "           1.51000000e+02,   1.85000002e+00,   1.27999997e+00,\n",
       "           1.40000001e-01,   2.84999990e+00,   1.27999997e+00,\n",
       "           7.18000000e+02], dtype=float32), 1),\n",
       " (array([  1.22900000e+01,   2.21000004e+00,   2.03999996e+01,\n",
       "           1.03000000e+02,   1.10000002e+00,   1.01999998e+00,\n",
       "           3.70000005e-01,   3.04999995e+00,   9.06000018e-01,\n",
       "           8.70000000e+02], dtype=float32), 1),\n",
       " (array([  1.38599997e+01,   2.67000008e+00,   2.50000000e+01,\n",
       "           8.60000000e+01,   2.95000005e+00,   2.85999990e+00,\n",
       "           2.09999993e-01,   3.38000011e+00,   1.36000001e+00,\n",
       "           4.10000000e+02], dtype=float32), 1),\n",
       " (array([  1.34899998e+01,   2.24000001e+00,   2.40000000e+01,\n",
       "           8.70000000e+01,   1.88000000e+00,   1.84000003e+00,\n",
       "           2.70000011e-01,   3.74000001e+00,   9.80000019e-01,\n",
       "           4.72000000e+02], dtype=float32), 1),\n",
       " (array([  1.29899998e+01,   2.59999990e+00,   3.00000000e+01,\n",
       "           1.39000000e+02,   3.29999995e+00,   2.89000010e+00,\n",
       "           2.09999993e-01,   3.34999990e+00,   1.30999994e+00,\n",
       "           9.85000000e+02], dtype=float32), 1),\n",
       " (array([  1.19600000e+01,   2.29999995e+00,   2.10000000e+01,\n",
       "           1.01000000e+02,   3.38000011e+00,   2.14000010e+00,\n",
       "           1.29999995e-01,   3.21000004e+00,   9.90000010e-01,\n",
       "           8.86000000e+02], dtype=float32), 1),\n",
       " (array([  1.16599998e+01,   1.91999996e+00,   1.60000000e+01,\n",
       "           9.70000000e+01,   1.61000001e+00,   1.57000005e+00,\n",
       "           3.40000004e-01,   3.79999995e+00,   1.23000002e+00,\n",
       "           4.28000000e+02], dtype=float32), 1),\n",
       " (array([  1.30299997e+01,   1.71000004e+00,   1.60000000e+01,\n",
       "           8.60000000e+01,   1.95000005e+00,   2.02999997e+00,\n",
       "           2.39999995e-01,   4.59999990e+00,   1.19000006e+00,\n",
       "           3.92000000e+02], dtype=float32), 1),\n",
       " (array([  1.18400002e+01,   2.23000002e+00,   1.80000000e+01,\n",
       "           1.12000000e+02,   1.72000003e+00,   1.32000005e+00,\n",
       "           4.30000007e-01,   2.65000010e+00,   9.59999979e-01,\n",
       "           5.00000000e+02], dtype=float32), 1),\n",
       " (array([  1.23299999e+01,   1.95000005e+00,   1.48000002e+01,\n",
       "           1.36000000e+02,   1.89999998e+00,   1.85000002e+00,\n",
       "           3.49999994e-01,   3.40000010e+00,   1.05999994e+00,\n",
       "           7.50000000e+02], dtype=float32), 1),\n",
       " (array([  1.26999998e+01,   2.40000010e+00,   2.30000000e+01,\n",
       "           1.01000000e+02,   2.82999992e+00,   2.54999995e+00,\n",
       "           4.30000007e-01,   2.56999993e+00,   1.19000006e+00,\n",
       "           4.63000000e+02], dtype=float32), 1),\n",
       " (array([  12.        ,    2.        ,   19.        ,   86.        ,\n",
       "            2.42000008,    2.25999999,    0.30000001,    2.5       ,\n",
       "            1.38      ,  278.        ], dtype=float32), 1),\n",
       " (array([  1.27200003e+01,   2.20000005e+00,   1.87999992e+01,\n",
       "           8.60000000e+01,   2.20000005e+00,   2.52999997e+00,\n",
       "           2.59999990e-01,   3.90000010e+00,   1.15999997e+00,\n",
       "           7.14000000e+02], dtype=float32), 1),\n",
       " (array([  1.20799999e+01,   2.50999999e+00,   2.40000000e+01,\n",
       "           7.80000000e+01,   2.00000000e+00,   1.58000004e+00,\n",
       "           4.00000006e-01,   2.20000005e+00,   1.30999994e+00,\n",
       "           6.30000000e+02], dtype=float32), 1),\n",
       " (array([  13.05000019,    2.31999993,   22.5       ,   85.        ,\n",
       "            1.64999998,    1.59000003,    0.61000001,    4.80000019,\n",
       "            0.83999997,  515.        ], dtype=float32), 1),\n",
       " (array([  1.18400002e+01,   2.57999992e+00,   1.80000000e+01,\n",
       "           9.40000000e+01,   2.20000005e+00,   2.21000004e+00,\n",
       "           2.19999999e-01,   3.04999995e+00,   7.90000021e-01,\n",
       "           5.20000000e+02], dtype=float32), 1),\n",
       " (array([  1.26700001e+01,   2.24000001e+00,   1.80000000e+01,\n",
       "           9.90000000e+01,   2.20000005e+00,   1.94000006e+00,\n",
       "           3.00000012e-01,   2.61999989e+00,   1.23000002e+00,\n",
       "           4.50000000e+02], dtype=float32), 1),\n",
       " (array([  1.21599998e+01,   2.30999994e+00,   2.27999992e+01,\n",
       "           9.00000000e+01,   1.77999997e+00,   1.69000006e+00,\n",
       "           4.30000007e-01,   2.45000005e+00,   1.33000004e+00,\n",
       "           4.95000000e+02], dtype=float32), 1),\n",
       " (array([  1.16499996e+01,   2.61999989e+00,   2.60000000e+01,\n",
       "           8.80000000e+01,   1.91999996e+00,   1.61000001e+00,\n",
       "           4.00000006e-01,   2.59999990e+00,   1.36000001e+00,\n",
       "           5.62000000e+02], dtype=float32), 1),\n",
       " (array([  1.16400003e+01,   2.46000004e+00,   2.16000004e+01,\n",
       "           8.40000000e+01,   1.95000005e+00,   1.69000006e+00,\n",
       "           4.79999989e-01,   2.79999995e+00,   1.00000000e+00,\n",
       "           6.80000000e+02], dtype=float32), 1),\n",
       " (array([  1.20799999e+01,   2.29999995e+00,   2.36000004e+01,\n",
       "           7.00000000e+01,   2.20000005e+00,   1.59000003e+00,\n",
       "           4.19999987e-01,   1.74000001e+00,   1.07000005e+00,\n",
       "           6.25000000e+02], dtype=float32), 1),\n",
       " (array([  12.07999992,    2.31999993,   18.5       ,   81.        ,\n",
       "            1.60000002,    1.5       ,    0.51999998,    2.4000001 ,\n",
       "            1.08000004,  480.        ], dtype=float32), 1),\n",
       " (array([  12.        ,    2.42000008,   22.        ,   86.        ,\n",
       "            1.45000005,    1.25      ,    0.5       ,    3.5999999 ,\n",
       "            1.04999995,  450.        ], dtype=float32), 1),\n",
       " (array([  12.68999958,    2.25999999,   20.70000076,   80.        ,\n",
       "            1.38      ,    1.46000004,    0.57999998,    3.04999995,\n",
       "            0.95999998,  495.        ], dtype=float32), 1),\n",
       " (array([  1.22900000e+01,   2.22000003e+00,   1.80000000e+01,\n",
       "           8.80000000e+01,   2.45000005e+00,   2.25000000e+00,\n",
       "           2.50000000e-01,   2.15000010e+00,   1.14999998e+00,\n",
       "           2.90000000e+02], dtype=float32), 1),\n",
       " (array([  1.16199999e+01,   2.27999997e+00,   1.80000000e+01,\n",
       "           9.80000000e+01,   3.01999998e+00,   2.25999999e+00,\n",
       "           1.70000002e-01,   3.25000000e+00,   1.15999997e+00,\n",
       "           3.45000000e+02], dtype=float32), 1),\n",
       " (array([  1.24700003e+01,   2.20000005e+00,   1.90000000e+01,\n",
       "           1.62000000e+02,   2.50000000e+00,   2.26999998e+00,\n",
       "           3.19999993e-01,   2.59999990e+00,   1.15999997e+00,\n",
       "           9.37000000e+02], dtype=float32), 1),\n",
       " (array([  1.18100004e+01,   2.74000001e+00,   2.15000000e+01,\n",
       "           1.34000000e+02,   1.60000002e+00,   9.90000010e-01,\n",
       "           1.40000001e-01,   2.50000000e+00,   9.49999988e-01,\n",
       "           6.25000000e+02], dtype=float32), 1),\n",
       " (array([  1.22900000e+01,   1.98000002e+00,   1.60000000e+01,\n",
       "           8.50000000e+01,   2.54999995e+00,   2.50000000e+00,\n",
       "           2.89999992e-01,   2.90000010e+00,   1.23000002e+00,\n",
       "           4.28000000e+02], dtype=float32), 1),\n",
       " (array([  1.23699999e+01,   2.09999990e+00,   1.85000000e+01,\n",
       "           8.80000000e+01,   3.51999998e+00,   3.75000000e+00,\n",
       "           2.39999995e-01,   4.50000000e+00,   1.03999996e+00,\n",
       "           6.60000000e+02], dtype=float32), 1),\n",
       " (array([  12.28999996,    2.21000004,   18.        ,   88.        ,\n",
       "            2.8499999 ,    2.99000001,    0.44999999,    2.29999995,\n",
       "            1.41999996,  406.        ], dtype=float32), 1),\n",
       " (array([  1.20799999e+01,   1.70000005e+00,   1.75000000e+01,\n",
       "           9.70000000e+01,   2.23000002e+00,   2.17000008e+00,\n",
       "           2.59999990e-01,   3.29999995e+00,   1.26999998e+00,\n",
       "           7.10000000e+02], dtype=float32), 1),\n",
       " (array([  1.26000004e+01,   1.89999998e+00,   1.85000000e+01,\n",
       "           8.80000000e+01,   1.45000005e+00,   1.36000001e+00,\n",
       "           2.89999992e-01,   2.45000005e+00,   1.03999996e+00,\n",
       "           5.62000000e+02], dtype=float32), 1),\n",
       " (array([  1.23400002e+01,   2.46000004e+00,   2.10000000e+01,\n",
       "           9.80000000e+01,   2.55999994e+00,   2.10999990e+00,\n",
       "           3.40000004e-01,   2.79999995e+00,   8.00000012e-01,\n",
       "           4.38000000e+02], dtype=float32), 1),\n",
       " (array([  1.18199997e+01,   1.88000000e+00,   1.95000000e+01,\n",
       "           8.60000000e+01,   2.50000000e+00,   1.63999999e+00,\n",
       "           3.70000005e-01,   2.05999994e+00,   9.39999998e-01,\n",
       "           4.15000000e+02], dtype=float32), 1),\n",
       " (array([  1.25100002e+01,   1.98000002e+00,   2.05000000e+01,\n",
       "           8.50000000e+01,   2.20000005e+00,   1.91999996e+00,\n",
       "           3.19999993e-01,   2.94000006e+00,   1.03999996e+00,\n",
       "           6.72000000e+02], dtype=float32), 1),\n",
       " (array([  12.42000008,    2.26999998,   22.        ,   90.        ,\n",
       "            1.67999995,    1.84000003,    0.66000003,    2.70000005,\n",
       "            0.86000001,  315.        ], dtype=float32), 1),\n",
       " (array([  1.22500000e+01,   2.11999989e+00,   1.90000000e+01,\n",
       "           8.00000000e+01,   1.64999998e+00,   2.02999997e+00,\n",
       "           3.70000005e-01,   3.40000010e+00,   1.00000000e+00,\n",
       "           5.10000000e+02], dtype=float32), 1),\n",
       " (array([  1.27200003e+01,   2.27999997e+00,   2.25000000e+01,\n",
       "           8.40000000e+01,   1.38000000e+00,   1.75999999e+00,\n",
       "           4.79999989e-01,   3.29999995e+00,   8.79999995e-01,\n",
       "           4.88000000e+02], dtype=float32), 1),\n",
       " (array([  12.22000027,    1.94000006,   19.        ,   92.        ,\n",
       "            2.3599999 ,    2.03999996,    0.38999999,    2.70000005,\n",
       "            0.86000001,  312.        ], dtype=float32), 1),\n",
       " (array([  1.16099997e+01,   2.70000005e+00,   2.00000000e+01,\n",
       "           9.40000000e+01,   2.74000001e+00,   2.92000008e+00,\n",
       "           2.89999992e-01,   2.65000010e+00,   9.59999979e-01,\n",
       "           6.80000000e+02], dtype=float32), 1),\n",
       " (array([  1.14600000e+01,   1.82000005e+00,   1.95000000e+01,\n",
       "           1.07000000e+02,   3.18000007e+00,   2.57999992e+00,\n",
       "           2.39999995e-01,   2.90000010e+00,   7.50000000e-01,\n",
       "           5.62000000e+02], dtype=float32), 1),\n",
       " (array([  1.25200005e+01,   2.17000008e+00,   2.10000000e+01,\n",
       "           8.80000000e+01,   2.54999995e+00,   2.26999998e+00,\n",
       "           2.59999990e-01,   2.00000000e+00,   8.99999976e-01,\n",
       "           3.25000000e+02], dtype=float32), 1),\n",
       " (array([  1.17600002e+01,   2.92000008e+00,   2.00000000e+01,\n",
       "           1.03000000e+02,   1.75000000e+00,   2.02999997e+00,\n",
       "           6.00000024e-01,   3.79999995e+00,   1.23000002e+00,\n",
       "           6.07000000e+02], dtype=float32), 1),\n",
       " (array([  1.14099998e+01,   2.50000000e+00,   2.10000000e+01,\n",
       "           8.80000000e+01,   2.48000002e+00,   2.00999999e+00,\n",
       "           4.19999987e-01,   3.07999992e+00,   1.10000002e+00,\n",
       "           4.34000000e+02], dtype=float32), 1),\n",
       " (array([  12.07999992,    2.5       ,   22.5       ,   84.        ,\n",
       "            2.55999994,    2.28999996,    0.43000001,    2.9000001 ,\n",
       "            0.93000001,  385.        ], dtype=float32), 1),\n",
       " (array([  11.02999973,    2.20000005,   21.5       ,   85.        ,\n",
       "            2.46000004,    2.17000008,    0.51999998,    1.89999998,\n",
       "            1.71000004,  407.        ], dtype=float32), 1),\n",
       " (array([  1.18199997e+01,   1.99000001e+00,   2.07999992e+01,\n",
       "           8.60000000e+01,   1.98000002e+00,   1.60000002e+00,\n",
       "           3.00000012e-01,   1.95000005e+00,   9.49999988e-01,\n",
       "           4.95000000e+02], dtype=float32), 1),\n",
       " (array([  1.24200001e+01,   2.19000006e+00,   2.25000000e+01,\n",
       "           1.08000000e+02,   2.00000000e+00,   2.08999991e+00,\n",
       "           3.40000004e-01,   2.05999994e+00,   1.05999994e+00,\n",
       "           3.45000000e+02], dtype=float32), 1),\n",
       " (array([  12.77000046,    1.98000002,   16.        ,   80.        ,\n",
       "            1.63      ,    1.25      ,    0.43000001,    3.4000001 ,\n",
       "            0.69999999,  372.        ], dtype=float32), 1),\n",
       " (array([  1.20000000e+01,   2.00000000e+00,   1.90000000e+01,\n",
       "           8.70000000e+01,   2.00000000e+00,   1.63999999e+00,\n",
       "           3.70000005e-01,   1.27999997e+00,   9.30000007e-01,\n",
       "           5.64000000e+02], dtype=float32), 1),\n",
       " (array([  1.14499998e+01,   2.42000008e+00,   2.00000000e+01,\n",
       "           9.60000000e+01,   2.90000010e+00,   2.78999996e+00,\n",
       "           3.19999993e-01,   3.25000000e+00,   8.00000012e-01,\n",
       "           6.25000000e+02], dtype=float32), 1),\n",
       " (array([  11.56000042,    3.23000002,   28.5       ,  119.        ,\n",
       "            3.18000007,    5.07999992,    0.47      ,    6.        ,\n",
       "            0.93000001,  465.        ], dtype=float32), 1),\n",
       " (array([  12.42000008,    2.73000002,   26.5       ,  102.        ,\n",
       "            2.20000005,    2.13000011,    0.43000001,    2.07999992,\n",
       "            0.92000002,  365.        ], dtype=float32), 1),\n",
       " (array([  1.30500002e+01,   2.13000011e+00,   2.15000000e+01,\n",
       "           8.60000000e+01,   2.61999989e+00,   2.65000010e+00,\n",
       "           3.00000012e-01,   2.59999990e+00,   7.30000019e-01,\n",
       "           3.80000000e+02], dtype=float32), 1),\n",
       " (array([  1.18699999e+01,   2.39000010e+00,   2.10000000e+01,\n",
       "           8.20000000e+01,   2.85999990e+00,   3.02999997e+00,\n",
       "           2.09999993e-01,   2.79999995e+00,   7.50000000e-01,\n",
       "           3.80000000e+02], dtype=float32), 1),\n",
       " (array([  1.20699997e+01,   2.17000008e+00,   2.10000000e+01,\n",
       "           8.50000000e+01,   2.59999990e+00,   2.65000010e+00,\n",
       "           3.70000005e-01,   2.75999999e+00,   8.60000014e-01,\n",
       "           3.78000000e+02], dtype=float32), 1),\n",
       " (array([  12.43000031,    2.28999996,   21.5       ,   86.        ,\n",
       "            2.74000001,    3.1500001 ,    0.38999999,    3.94000006,\n",
       "            0.69      ,  352.        ], dtype=float32), 1),\n",
       " (array([  11.78999996,    2.77999997,   28.5       ,   92.        ,\n",
       "            2.13000011,    2.24000001,    0.57999998,    3.        ,\n",
       "            0.97000003,  466.        ], dtype=float32), 1),\n",
       " (array([  12.36999989,    2.29999995,   24.5       ,   88.        ,\n",
       "            2.22000003,    2.45000005,    0.40000001,    2.11999989,\n",
       "            0.88999999,  342.        ], dtype=float32), 1),\n",
       " (array([  1.20400000e+01,   2.38000011e+00,   2.20000000e+01,\n",
       "           8.00000000e+01,   2.09999990e+00,   1.75000000e+00,\n",
       "           4.19999987e-01,   2.59999990e+00,   7.90000021e-01,\n",
       "           5.80000000e+02], dtype=float32), 1),\n",
       " (array([  1.28599997e+01,   2.31999993e+00,   1.80000000e+01,\n",
       "           1.22000000e+02,   1.50999999e+00,   1.25000000e+00,\n",
       "           2.09999993e-01,   4.09999990e+00,   7.59999990e-01,\n",
       "           6.30000000e+02], dtype=float32), 2),\n",
       " (array([  1.28800001e+01,   2.40000010e+00,   2.00000000e+01,\n",
       "           1.04000000e+02,   1.29999995e+00,   1.22000003e+00,\n",
       "           2.39999995e-01,   5.40000010e+00,   7.40000010e-01,\n",
       "           5.30000000e+02], dtype=float32), 2),\n",
       " (array([  1.28100004e+01,   2.40000010e+00,   2.40000000e+01,\n",
       "           9.80000000e+01,   1.14999998e+00,   1.09000003e+00,\n",
       "           2.70000011e-01,   5.69999981e+00,   6.60000026e-01,\n",
       "           5.60000000e+02], dtype=float32), 2),\n",
       " (array([  1.26999998e+01,   2.35999990e+00,   2.15000000e+01,\n",
       "           1.06000000e+02,   1.70000005e+00,   1.20000005e+00,\n",
       "           1.70000002e-01,   5.00000000e+00,   7.79999971e-01,\n",
       "           6.00000000e+02], dtype=float32), 2),\n",
       " (array([  1.25100002e+01,   2.25000000e+00,   1.75000000e+01,\n",
       "           8.50000000e+01,   2.00000000e+00,   5.79999983e-01,\n",
       "           6.00000024e-01,   5.44999981e+00,   7.50000000e-01,\n",
       "           6.50000000e+02], dtype=float32), 2),\n",
       " (array([  1.26000004e+01,   2.20000005e+00,   1.85000000e+01,\n",
       "           9.40000000e+01,   1.62000000e+00,   6.60000026e-01,\n",
       "           6.29999995e-01,   7.09999990e+00,   7.30000019e-01,\n",
       "           6.95000000e+02], dtype=float32), 2),\n",
       " (array([  1.22500000e+01,   2.53999996e+00,   2.10000000e+01,\n",
       "           8.90000000e+01,   1.38000000e+00,   4.69999999e-01,\n",
       "           5.29999971e-01,   3.84999990e+00,   7.50000000e-01,\n",
       "           7.20000000e+02], dtype=float32), 2),\n",
       " (array([  12.52999973,    2.6400001 ,   25.        ,   96.        ,\n",
       "            1.78999996,    0.60000002,    0.63      ,    5.        ,\n",
       "            0.81999999,  515.        ], dtype=float32), 2),\n",
       " (array([  1.34899998e+01,   2.19000006e+00,   1.95000000e+01,\n",
       "           8.80000000e+01,   1.62000000e+00,   4.79999989e-01,\n",
       "           5.79999983e-01,   5.69999981e+00,   8.10000002e-01,\n",
       "           5.80000000e+02], dtype=float32), 2),\n",
       " (array([  1.28400002e+01,   2.60999990e+00,   2.40000000e+01,\n",
       "           1.01000000e+02,   2.31999993e+00,   6.00000024e-01,\n",
       "           5.29999971e-01,   4.92000008e+00,   8.89999986e-01,\n",
       "           5.90000000e+02], dtype=float32), 2),\n",
       " (array([  1.29300003e+01,   2.70000005e+00,   2.10000000e+01,\n",
       "           9.60000000e+01,   1.53999996e+00,   5.00000000e-01,\n",
       "           5.29999971e-01,   4.59999990e+00,   7.69999981e-01,\n",
       "           6.00000000e+02], dtype=float32), 2),\n",
       " (array([  1.33599997e+01,   2.34999990e+00,   2.00000000e+01,\n",
       "           8.90000000e+01,   1.39999998e+00,   5.00000000e-01,\n",
       "           3.70000005e-01,   5.59999990e+00,   6.99999988e-01,\n",
       "           7.80000000e+02], dtype=float32), 2),\n",
       " (array([  1.35200005e+01,   2.72000003e+00,   2.35000000e+01,\n",
       "           9.70000000e+01,   1.54999995e+00,   5.19999981e-01,\n",
       "           5.00000000e-01,   4.34999990e+00,   8.89999986e-01,\n",
       "           5.20000000e+02], dtype=float32), 2),\n",
       " (array([  1.36199999e+01,   2.34999990e+00,   2.00000000e+01,\n",
       "           9.20000000e+01,   2.00000000e+00,   8.00000012e-01,\n",
       "           4.69999999e-01,   4.40000010e+00,   9.10000026e-01,\n",
       "           5.50000000e+02], dtype=float32), 2),\n",
       " (array([  1.22500000e+01,   2.20000005e+00,   1.85000000e+01,\n",
       "           1.12000000e+02,   1.38000000e+00,   7.79999971e-01,\n",
       "           2.89999992e-01,   8.21000004e+00,   6.49999976e-01,\n",
       "           8.55000000e+02], dtype=float32), 2),\n",
       " (array([  1.31599998e+01,   2.15000010e+00,   2.10000000e+01,\n",
       "           1.02000000e+02,   1.50000000e+00,   5.50000012e-01,\n",
       "           4.30000007e-01,   4.00000000e+00,   6.00000024e-01,\n",
       "           8.30000000e+02], dtype=float32), 2),\n",
       " (array([  1.38800001e+01,   2.23000002e+00,   2.00000000e+01,\n",
       "           8.00000000e+01,   9.80000019e-01,   3.40000004e-01,\n",
       "           4.00000006e-01,   4.90000010e+00,   5.79999983e-01,\n",
       "           4.15000000e+02], dtype=float32), 2),\n",
       " (array([  1.28699999e+01,   2.48000002e+00,   2.15000000e+01,\n",
       "           8.60000000e+01,   1.70000005e+00,   6.49999976e-01,\n",
       "           4.69999999e-01,   7.65000010e+00,   5.40000021e-01,\n",
       "           6.25000000e+02], dtype=float32), 2),\n",
       " (array([  1.33199997e+01,   2.38000011e+00,   2.15000000e+01,\n",
       "           9.20000000e+01,   1.92999995e+00,   7.59999990e-01,\n",
       "           4.49999988e-01,   8.42000008e+00,   5.50000012e-01,\n",
       "           6.50000000e+02], dtype=float32), 2),\n",
       " (array([  1.30799999e+01,   2.35999990e+00,   2.15000000e+01,\n",
       "           1.13000000e+02,   1.40999997e+00,   1.38999999e+00,\n",
       "           3.40000004e-01,   9.39999962e+00,   5.69999993e-01,\n",
       "           5.50000000e+02], dtype=float32), 2),\n",
       " (array([  1.35000000e+01,   2.61999989e+00,   2.40000000e+01,\n",
       "           1.23000000e+02,   1.39999998e+00,   1.57000005e+00,\n",
       "           2.19999999e-01,   8.60000038e+00,   5.89999974e-01,\n",
       "           5.00000000e+02], dtype=float32), 2),\n",
       " (array([  1.27900000e+01,   2.48000002e+00,   2.20000000e+01,\n",
       "           1.12000000e+02,   1.48000002e+00,   1.36000001e+00,\n",
       "           2.39999995e-01,   1.08000002e+01,   4.79999989e-01,\n",
       "           4.80000000e+02], dtype=float32), 2),\n",
       " (array([  1.31099997e+01,   2.75000000e+00,   2.55000000e+01,\n",
       "           1.16000000e+02,   2.20000005e+00,   1.27999997e+00,\n",
       "           2.59999990e-01,   7.09999990e+00,   6.10000014e-01,\n",
       "           4.25000000e+02], dtype=float32), 2),\n",
       " (array([  1.32299995e+01,   2.27999997e+00,   1.85000000e+01,\n",
       "           9.80000000e+01,   1.79999995e+00,   8.29999983e-01,\n",
       "           6.10000014e-01,   1.05200005e+01,   5.60000002e-01,\n",
       "           6.75000000e+02], dtype=float32), 2),\n",
       " (array([  1.25799999e+01,   2.09999990e+00,   2.00000000e+01,\n",
       "           1.03000000e+02,   1.48000002e+00,   5.79999983e-01,\n",
       "           5.29999971e-01,   7.59999990e+00,   5.79999983e-01,\n",
       "           6.40000000e+02], dtype=float32), 2),\n",
       " (array([  1.31700001e+01,   2.31999993e+00,   2.20000000e+01,\n",
       "           9.30000000e+01,   1.74000001e+00,   6.29999995e-01,\n",
       "           6.10000014e-01,   7.90000010e+00,   6.00000024e-01,\n",
       "           7.25000000e+02], dtype=float32), 2),\n",
       " (array([  13.84000015,    2.38000011,   19.5       ,   89.        ,\n",
       "            1.79999995,    0.82999998,    0.47999999,    9.01000023,\n",
       "            0.56999999,  480.        ], dtype=float32), 2),\n",
       " (array([  1.24499998e+01,   2.64000010e+00,   2.70000000e+01,\n",
       "           9.70000000e+01,   1.89999998e+00,   5.79999983e-01,\n",
       "           6.29999995e-01,   7.50000000e+00,   6.70000017e-01,\n",
       "           8.80000000e+02], dtype=float32), 2),\n",
       " (array([  1.43400002e+01,   2.70000005e+00,   2.50000000e+01,\n",
       "           9.80000000e+01,   2.79999995e+00,   1.30999994e+00,\n",
       "           5.29999971e-01,   1.30000000e+01,   5.69999993e-01,\n",
       "           6.60000000e+02], dtype=float32), 2),\n",
       " (array([  1.34799995e+01,   2.64000010e+00,   2.25000000e+01,\n",
       "           8.90000000e+01,   2.59999990e+00,   1.10000002e+00,\n",
       "           5.19999981e-01,   1.17500000e+01,   5.69999993e-01,\n",
       "           6.20000000e+02], dtype=float32), 2),\n",
       " (array([  1.23599997e+01,   2.38000011e+00,   2.10000000e+01,\n",
       "           8.80000000e+01,   2.29999995e+00,   9.20000017e-01,\n",
       "           5.00000000e-01,   7.65000010e+00,   5.60000002e-01,\n",
       "           5.20000000e+02], dtype=float32), 2),\n",
       " (array([  1.36899996e+01,   2.53999996e+00,   2.00000000e+01,\n",
       "           1.07000000e+02,   1.83000004e+00,   5.60000002e-01,\n",
       "           5.00000000e-01,   5.88000011e+00,   9.59999979e-01,\n",
       "           6.80000000e+02], dtype=float32), 2),\n",
       " (array([  12.85000038,    2.57999992,   22.        ,  106.        ,\n",
       "            1.64999998,    0.60000002,    0.60000002,    5.57999992,\n",
       "            0.87      ,  570.        ], dtype=float32), 2),\n",
       " (array([  1.29600000e+01,   2.34999990e+00,   1.85000000e+01,\n",
       "           1.06000000e+02,   1.38999999e+00,   6.99999988e-01,\n",
       "           4.00000006e-01,   5.28000021e+00,   6.80000007e-01,\n",
       "           6.75000000e+02], dtype=float32), 2),\n",
       " (array([  1.37799997e+01,   2.29999995e+00,   2.20000000e+01,\n",
       "           9.00000000e+01,   1.35000002e+00,   6.80000007e-01,\n",
       "           4.09999996e-01,   9.57999992e+00,   6.99999988e-01,\n",
       "           6.15000000e+02], dtype=float32), 2),\n",
       " (array([  1.37299995e+01,   2.25999999e+00,   2.25000000e+01,\n",
       "           8.80000000e+01,   1.27999997e+00,   4.69999999e-01,\n",
       "           5.19999981e-01,   6.61999989e+00,   7.79999971e-01,\n",
       "           5.20000000e+02], dtype=float32), 2),\n",
       " (array([  1.34499998e+01,   2.59999990e+00,   2.30000000e+01,\n",
       "           1.11000000e+02,   1.70000005e+00,   9.20000017e-01,\n",
       "           4.30000007e-01,   1.06800003e+01,   8.50000024e-01,\n",
       "           6.95000000e+02], dtype=float32), 2),\n",
       " (array([  1.28199997e+01,   2.29999995e+00,   1.95000000e+01,\n",
       "           8.80000000e+01,   1.48000002e+00,   6.60000026e-01,\n",
       "           4.00000006e-01,   1.02600002e+01,   7.20000029e-01,\n",
       "           6.85000000e+02], dtype=float32), 2),\n",
       " (array([  1.35799999e+01,   2.69000006e+00,   2.45000000e+01,\n",
       "           1.05000000e+02,   1.54999995e+00,   8.39999974e-01,\n",
       "           3.89999986e-01,   8.65999985e+00,   7.40000010e-01,\n",
       "           7.50000000e+02], dtype=float32), 2),\n",
       " (array([  1.33999996e+01,   2.85999990e+00,   2.50000000e+01,\n",
       "           1.12000000e+02,   1.98000002e+00,   9.59999979e-01,\n",
       "           2.70000011e-01,   8.50000000e+00,   6.70000017e-01,\n",
       "           6.30000000e+02], dtype=float32), 2),\n",
       " (array([  1.21999998e+01,   2.31999993e+00,   1.90000000e+01,\n",
       "           9.60000000e+01,   1.25000000e+00,   4.90000010e-01,\n",
       "           4.00000006e-01,   5.50000000e+00,   6.60000026e-01,\n",
       "           5.10000000e+02], dtype=float32), 2),\n",
       " (array([  12.77000046,    2.27999997,   19.5       ,   86.        ,\n",
       "            1.38999999,    0.50999999,    0.47999999,    9.89999866,\n",
       "            0.56999999,  470.        ], dtype=float32), 2),\n",
       " (array([  1.41599998e+01,   2.48000002e+00,   2.00000000e+01,\n",
       "           9.10000000e+01,   1.67999995e+00,   6.99999988e-01,\n",
       "           4.39999998e-01,   9.69999981e+00,   6.20000005e-01,\n",
       "           6.60000000e+02], dtype=float32), 2),\n",
       " (array([  1.37100000e+01,   2.45000005e+00,   2.05000000e+01,\n",
       "           9.50000000e+01,   1.67999995e+00,   6.10000014e-01,\n",
       "           5.19999981e-01,   7.69999981e+00,   6.39999986e-01,\n",
       "           7.40000000e+02], dtype=float32), 2),\n",
       " (array([  1.33999996e+01,   2.48000002e+00,   2.30000000e+01,\n",
       "           1.02000000e+02,   1.79999995e+00,   7.50000000e-01,\n",
       "           4.30000007e-01,   7.30000019e+00,   6.99999988e-01,\n",
       "           7.50000000e+02], dtype=float32), 2),\n",
       " (array([  1.32700005e+01,   2.25999999e+00,   2.00000000e+01,\n",
       "           1.20000000e+02,   1.59000003e+00,   6.89999998e-01,\n",
       "           4.30000007e-01,   1.01999998e+01,   5.89999974e-01,\n",
       "           8.35000000e+02], dtype=float32), 2),\n",
       " (array([  1.31700001e+01,   2.36999989e+00,   2.00000000e+01,\n",
       "           1.20000000e+02,   1.64999998e+00,   6.80000007e-01,\n",
       "           5.29999971e-01,   9.30000019e+00,   6.00000024e-01,\n",
       "           8.40000000e+02], dtype=float32), 2),\n",
       " (array([  14.13000011,    2.74000001,   24.5       ,   96.        ,\n",
       "            2.04999995,    0.75999999,    0.56      ,    9.19999981,\n",
       "            0.61000001,  560.        ], dtype=float32), 2)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練データと検証データに分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chainerではデータセットをランダムに分割に関する関数が準備されており、chainer.datasets.split_dataset_randomです。  \n",
    "※ 詳しくは[こちら](https://docs.chainer.org/en/stable/reference/generated/chainer.datasets.split_dataset_random.html#chainer.datasets.split_dataset_random)のリファレンス参照\n",
    "\n",
    "<img src=\"./images/07.png\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prameterには、dataset（先ほど作成した形式）とfirst_sizeと指定されています。\n",
    "\n",
    "first_sizeでは訓練データのサイズを指定するのですが、こちらの指定をする際に、全体の70%を訓練データにしようと決めておくと記述が簡単かつ汎用性の高いプログラムになります。\n",
    "\n",
    "全体のサイズを取得する時にはlen()が便利です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split_dataset_randomを使用したtrainとtestの分割は以下のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chainer.datasets import split_dataset_random\n",
    "\n",
    "n_train = int( len(dataset) * 0.7 )  # 訓練データのサイズ\n",
    "train, test = split_dataset_random(dataset, n_train, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_trainを計算する際に、intと付けていますが、サイズは整数値しか受け付けないため、少数が出た際にはintによって小数値の切り捨てをおこなっています。\n",
    "\n",
    "また、seed=1は乱数のシードを1で固定しますといった意味で、何度か出てきている再現性確保のためです。\n",
    "\n",
    "出力として得られるtrainとtestを確認してみると、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.datasets.sub_dataset.SubDataset at 0x11348c470>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "と表示されるため、「あれ？数値はどこにいったのかな」と迷いますが、train[0]のようにリストの要素番号を指定すると、数値が表示され、リスト形式で保存されていることがわかります。  \n",
    "※このあたりは、なかなかリファレンスがなかったりするため、挙動を確認しながら進めていくことが必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.36899996e+01,   2.53999996e+00,   2.00000000e+01,\n",
       "          1.07000000e+02,   1.83000004e+00,   5.60000002e-01,\n",
       "          5.00000000e-01,   5.88000011e+00,   9.59999979e-01,\n",
       "          6.80000000e+02], dtype=float32), 2)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.datasets.sub_dataset.SubDataset at 0x11348c6d8>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  12.17000008,    2.52999997,   19.        ,  104.        ,\n",
       "           1.88999999,    1.75      ,    0.44999999,    2.95000005,\n",
       "           1.45000005,  355.        ], dtype=float32), 1)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteratorの設定\n",
    "\n",
    "**Iterator**では「**バッチサイズ**」を決めることができます。\n",
    "\n",
    "順伝播で評価関数を計算する際に、全てのサンプルを使用するのではなく、基本的には、**ミニバッチ**と呼ばれるサンプルの一部のデータセットのみで、評価関数の計算を行い、逆伝播で勾配情報を計算し、最適化アルゴリズム（SGDやAdam等）によりパラメータの学習を行います。\n",
    "\n",
    "### ミニバッチを採用する理由\n",
    "\n",
    "たとえば、10万サンプルある場合は、10万回順伝播を計算して、初めて1回パラメータ更新できるといったように、サンプル数が多ければ多いほど１回あたりのパラメータ更新にかかる時間が長くなってしまうといった問題を避けられます。\n",
    "バッチサイズを10としておけば、ほとんど同じ計算負荷でも1万回のパラメータ更新を行うことができます（厳密には逆伝播が毎回走るため同じ計算負荷ではない）。\n",
    "\n",
    "また、もう一つの理由として、ミニバッチに分けて最適化を行うことで、局所最適解に陥ることを避けられると言われています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はこのバッチサイズを20と設定して行きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize = 20\n",
    "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
    "test_iter  = chainer.iterators.SerialIterator(test,  batchsize, repeat=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updaterの設定\n",
    "\n",
    "Updaterでは、Optimizerの設定や、使用するデバイス（CPUやGPU）の設定を行えます。\n",
    "\n",
    "- CPUを使用する場合には、device=-1とオプションに指定しましょう。\n",
    "- GPUを使用する場合には、device=0（GPUを複数枚さしている場合はdevice=1なども存在）とオプションで明示しておきましょう。\n",
    "\n",
    "deviceを特に指定しない場合には、CPUが使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chainer import training\n",
    "updater = training.StandardUpdater(train_iter, optimizer, device=-1)\n",
    "# updater = training.StandardUpdater(train_iter, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainerとextensionsの設定\n",
    "Trainerでは、**エポック（ミニバッチを全て処理して１エポック）**の回数や、そのextensionsでオプションを指定することにより、**結果をログ出力や標準出力（インタラクティブに表示）**もできたりします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainerとそのextensionsの設定\n",
    "from chainer.training import extensions\n",
    "\n",
    "# trainerの基本設定\n",
    "epoch = 1000\n",
    "trainer = training.Trainer(updater, (epoch, 'epoch'), out='result')\n",
    "\n",
    "# 検証データで評価\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, device=-1))\n",
    "\n",
    "# 学習結果の途中を表示する\n",
    "trainer.extend(extensions.LogReport(trigger=(1, 'epoch')))\n",
    "\n",
    "# １エポックごとに、trainデータに対するlossと、testデータに対するloss、経過時間（elapsed_time）を標準出力させる\n",
    "trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'validation/main/loss', 'elapsed_time']), trigger=(1, 'epoch'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の実行\n",
    "色々と設定を行い、Trainerでは最後に trainer.run() でOKです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   validation/main/loss  elapsed_time\n",
      "\u001b[J1           15.7672     14.2523               0.0204601     \n",
      "\u001b[J2           13.3503     12.5375               0.0347712     \n",
      "\u001b[J3           12.0078     11.0668               0.049818      \n",
      "\u001b[J4           10.174      9.61617               0.0651011     \n",
      "\u001b[J5           8.77633     8.20031               0.0863202     \n",
      "\u001b[J6           7.47279     6.46364               0.101881      \n",
      "\u001b[J7           5.65272     4.9057                0.115553      \n",
      "\u001b[J8           4.37566     3.70569               0.131015      \n",
      "\u001b[J9           2.96045     2.68607               0.144884      \n",
      "\u001b[J10          2.18111     1.88635               0.163925      \n",
      "\u001b[J11          1.71607     1.49578               0.187345      \n",
      "\u001b[J12          1.42262     1.37366               0.208987      \n",
      "\u001b[J13          1.35401     1.23788               0.22583       \n",
      "\u001b[J14          1.19969     1.13354               0.240829      \n",
      "\u001b[J15          1.12737     1.06224               0.255255      \n",
      "\u001b[J16          1.10141     1.0085                0.27646       \n",
      "\u001b[J17          1.01607     0.975706              0.296999      \n",
      "\u001b[J18          0.943047    0.963266              0.312827      \n",
      "\u001b[J19          0.945658    0.938661              0.326113      \n",
      "\u001b[J20          0.925852    0.922611              0.337834      \n",
      "\u001b[J21          0.906179    0.915853              0.351253      \n",
      "\u001b[J22          0.866938    0.905177              0.363426      \n",
      "\u001b[J23          0.858738    0.889851              0.375465      \n",
      "\u001b[J24          0.837249    0.885791              0.38776       \n",
      "\u001b[J25          0.852619    0.856788              0.399663      \n",
      "\u001b[J26          0.831638    0.870832              0.413102      \n",
      "\u001b[J27          0.782077    0.843597              0.424628      \n",
      "\u001b[J28          0.835115    0.831262              0.438299      \n",
      "\u001b[J29          0.772933    0.856222              0.450943      \n",
      "\u001b[J30          0.810015    0.82852               0.469701      \n",
      "\u001b[J31          0.796734    0.807174              0.484377      \n",
      "\u001b[J32          0.751022    0.820135              0.498911      \n",
      "\u001b[J33          0.72716     0.823868              0.510698      \n",
      "\u001b[J34          0.773825    0.796114              0.523668      \n",
      "\u001b[J35          0.743825    0.798411              0.535744      \n",
      "\u001b[J36          0.736119    0.808466              0.549581      \n",
      "\u001b[J37          0.742908    0.787518              0.56185       \n",
      "\u001b[J38          0.722947    0.7793                0.573218      \n",
      "\u001b[J39          0.706121    0.778957              0.585242      \n",
      "\u001b[J40          0.713209    0.779284              0.597388      \n",
      "\u001b[J41          0.703094    0.779431              0.610489      \n",
      "\u001b[J42          0.6862      0.774346              0.621364      \n",
      "\u001b[J43          0.700637    0.76684               0.635436      \n",
      "\u001b[J44          0.703086    0.760519              0.655353      \n",
      "\u001b[J45          0.691179    0.764719              0.674477      \n",
      "\u001b[J46          0.672736    0.751779              0.697479      \n",
      "\u001b[J47          0.670737    0.754631              0.716253      \n",
      "\u001b[J48          0.708742    0.745453              0.732605      \n",
      "\u001b[J49          0.692149    0.75106               0.748927      \n",
      "\u001b[J50          0.646548    0.742899              0.764606      \n",
      "\u001b[J51          0.642588    0.731351              0.78341       \n",
      "\u001b[J52          0.690679    0.733553              0.803152      \n",
      "\u001b[J53          0.644585    0.731614              0.819579      \n",
      "\u001b[J54          0.673405    0.731231              0.83569       \n",
      "\u001b[J55          0.642413    0.728884              0.853511      \n",
      "\u001b[J56          0.650266    0.726211              0.872342      \n",
      "\u001b[J57          0.647791    0.709584              0.890282      \n",
      "\u001b[J58          0.652518    0.708164              0.908251      \n",
      "\u001b[J59          0.618469    0.73868               0.928024      \n",
      "\u001b[J60          0.647412    0.716446              0.946658      \n",
      "\u001b[J61          0.616736    0.697514              0.965196      \n",
      "\u001b[J62          0.660267    0.71171               0.978448      \n",
      "\u001b[J63          0.626266    0.708043              0.991563      \n",
      "\u001b[J64          0.617325    0.691614              1.00476       \n",
      "\u001b[J65          0.625218    0.694376              1.01836       \n",
      "\u001b[J66          0.626515    0.708031              1.03309       \n",
      "\u001b[J67          0.617019    0.680569              1.04569       \n",
      "\u001b[J68          0.627283    0.691542              1.05714       \n",
      "\u001b[J69          0.603315    0.691641              1.06965       \n",
      "\u001b[J70          0.621237    0.701556              1.08305       \n",
      "\u001b[J71          0.589939    0.681264              1.09787       \n",
      "\u001b[J72          0.614826    0.672678              1.11589       \n",
      "\u001b[J73          0.617224    0.669846              1.1321        \n",
      "\u001b[J74          0.59488     0.677022              1.1473        \n",
      "\u001b[J75          0.586364    0.679059              1.16252       \n",
      "\u001b[J76          0.614234    0.674178              1.18364       \n",
      "\u001b[J77          0.578194    0.672491              1.19794       \n",
      "\u001b[J78          0.587796    0.656024              1.21216       \n",
      "\u001b[J79          0.575776    0.662393              1.22604       \n",
      "\u001b[J80          0.591439    0.669658              1.23952       \n",
      "\u001b[J81          0.596092    0.65945               1.25386       \n",
      "\u001b[J82          0.559855    0.654391              1.26639       \n",
      "\u001b[J83          0.591489    0.658976              1.2795        \n",
      "\u001b[J84          0.567151    0.675008              1.29316       \n",
      "\u001b[J85          0.587039    0.655533              1.30786       \n",
      "\u001b[J86          0.616605    0.642022              1.32652       \n",
      "\u001b[J87          0.527041    0.66892               1.34403       \n",
      "\u001b[J88          0.596032    0.648034              1.35857       \n",
      "\u001b[J89          0.550277    0.642392              1.37154       \n",
      "\u001b[J90          0.573683    0.640233              1.38505       \n",
      "\u001b[J91          0.555815    0.653779              1.40032       \n",
      "\u001b[J92          0.601826    0.629601              1.41389       \n",
      "\u001b[J93          0.539636    0.643764              1.42768       \n",
      "\u001b[J94          0.549519    0.628248              1.44113       \n",
      "\u001b[J95          0.569072    0.641602              1.45478       \n",
      "\u001b[J96          0.5666      0.646587              1.46937       \n",
      "\u001b[J97          0.529927    0.61829               1.48255       \n",
      "\u001b[J98          0.560912    0.626019              1.49489       \n",
      "\u001b[J99          0.553097    0.653128              1.50916       \n",
      "\u001b[J100         0.549774    0.617032              1.5241        \n",
      "\u001b[J101         0.576393    0.614639              1.5432        \n",
      "\u001b[J102         0.488215    0.641435              1.56156       \n",
      "\u001b[J103         0.577247    0.62438               1.57796       \n",
      "\u001b[J104         0.551859    0.607588              1.59227       \n",
      "\u001b[J105         0.518473    0.629777              1.60629       \n",
      "\u001b[J106         0.52228     0.617746              1.62139       \n",
      "\u001b[J107         0.544205    0.604582              1.63678       \n",
      "\u001b[J108         0.521928    0.616042              1.65097       \n",
      "\u001b[J109         0.551464    0.607708              1.66558       \n",
      "\u001b[J110         0.508834    0.595694              1.68052       \n",
      "\u001b[J111         0.51094     0.60666               1.69846       \n",
      "\u001b[J112         0.508587    0.614141              1.71676       \n",
      "\u001b[J113         0.55574     0.596117              1.73396       \n",
      "\u001b[J114         0.495811    0.593103              1.75714       \n",
      "\u001b[J115         0.517853    0.604692              1.77695       \n",
      "\u001b[J116         0.503421    0.603426              1.8037        \n",
      "\u001b[J117         0.551887    0.585791              1.82217       \n",
      "\u001b[J118         0.468829    0.598852              1.83743       \n",
      "\u001b[J119         0.528657    0.583555              1.85312       \n",
      "\u001b[J120         0.494581    0.576615              1.86816       \n",
      "\u001b[J121         0.508143    0.601264              1.88386       \n",
      "\u001b[J122         0.49242     0.585682              1.89891       \n",
      "\u001b[J123         0.506475    0.5736                1.91365       \n",
      "\u001b[J124         0.500098    0.569074              1.92778       \n",
      "\u001b[J125         0.496066    0.584481              1.94369       \n",
      "\u001b[J126         0.489008    0.590407              1.96277       \n",
      "\u001b[J127         0.503101    0.568903              1.97848       \n",
      "\u001b[J128         0.498316    0.571041              1.99358       \n",
      "\u001b[J129         0.481129    0.566695              2.00743       \n",
      "\u001b[J130         0.481713    0.569173              2.02289       \n",
      "\u001b[J131         0.487163    0.564509              2.03832       \n",
      "\u001b[J132         0.477827    0.563598              2.05222       \n",
      "\u001b[J133         0.501041    0.549638              2.06648       \n",
      "\u001b[J134         0.452413    0.560775              2.08136       \n",
      "\u001b[J135         0.476789    0.57742               2.09528       \n",
      "\u001b[J136         0.459648    0.558967              2.11031       \n",
      "\u001b[J137         0.495142    0.552991              2.12408       \n",
      "\u001b[J138         0.47645     0.549767              2.14035       \n",
      "\u001b[J139         0.466221    0.546844              2.15502       \n",
      "\u001b[J140         0.453238    0.543169              2.17237       \n",
      "\u001b[J141         0.466437    0.544094              2.19195       \n",
      "\u001b[J142         0.453863    0.540932              2.20728       \n",
      "\u001b[J143         0.478548    0.557772              2.22347       \n",
      "\u001b[J144         0.453366    0.549596              2.24312       \n",
      "\u001b[J145         0.462467    0.528788              2.25971       \n",
      "\u001b[J146         0.495935    0.550652              2.27682       \n",
      "\u001b[J147         0.436897    0.53359               2.29218       \n",
      "\u001b[J148         0.420871    0.522866              2.3072        \n",
      "\u001b[J149         0.468632    0.546051              2.32205       \n",
      "\u001b[J150         0.446807    0.532638              2.338         \n",
      "\u001b[J151         0.458324    0.519813              2.35586       \n",
      "\u001b[J152         0.402864    0.540237              2.37176       \n",
      "\u001b[J153         0.490004    0.518024              2.39297       \n",
      "\u001b[J154         0.440098    0.52133               2.41017       \n",
      "\u001b[J155         0.416782    0.523078              2.42613       \n",
      "\u001b[J156         0.439018    0.515715              2.44289       \n",
      "\u001b[J157         0.418871    0.516625              2.45852       \n",
      "\u001b[J158         0.454736    0.510913              2.47341       \n",
      "\u001b[J159         0.41835     0.524095              2.48852       \n",
      "\u001b[J160         0.439336    0.513556              2.50331       \n",
      "\u001b[J161         0.413827    0.499636              2.51896       \n",
      "\u001b[J162         0.435234    0.494639              2.53308       \n",
      "\u001b[J163         0.433521    0.528197              2.54961       \n",
      "\u001b[J164         0.435007    0.511408              2.56423       \n",
      "\u001b[J165         0.419       0.495821              2.58089       \n",
      "\u001b[J166         0.435673    0.518355              2.60059       \n",
      "\u001b[J167         0.431335    0.493265              2.61749       \n",
      "\u001b[J168         0.373018    0.480862              2.63461       \n",
      "\u001b[J169         0.426447    0.496831              2.65109       \n",
      "\u001b[J170         0.424587    0.520748              2.66632       \n",
      "\u001b[J171         0.438301    0.479327              2.68269       \n",
      "\u001b[J172         0.385414    0.484087              2.69904       \n",
      "\u001b[J173         0.375784    0.498683              2.7137        \n",
      "\u001b[J174         0.412452    0.490856              2.72861       \n",
      "\u001b[J175         0.413212    0.471489              2.74407       \n",
      "\u001b[J176         0.398644    0.495431              2.76409       \n",
      "\u001b[J177         0.421811    0.480675              2.78377       \n",
      "\u001b[J178         0.36499     0.474498              2.80427       \n",
      "\u001b[J179         0.421167    0.472745              2.82248       \n",
      "\u001b[J180         0.38177     0.473659              2.83839       \n",
      "\u001b[J181         0.38591     0.48096               2.85744       \n",
      "\u001b[J182         0.406395    0.464622              2.87307       \n",
      "\u001b[J183         0.369758    0.457007              2.88864       \n",
      "\u001b[J184         0.385729    0.469662              2.90428       \n",
      "\u001b[J185         0.386913    0.467863              2.91873       \n",
      "\u001b[J186         0.383       0.457997              2.93542       \n",
      "\u001b[J187         0.396057    0.46157               2.95014       \n",
      "\u001b[J188         0.401253    0.464697              2.96495       \n",
      "\u001b[J189         0.341207    0.454353              2.98055       \n",
      "\u001b[J190         0.382901    0.450244              2.9979        \n",
      "\u001b[J191         0.394544    0.44501               3.0177        \n",
      "\u001b[J192         0.376236    0.469489              3.03425       \n",
      "\u001b[J193         0.358491    0.450558              3.05066       \n",
      "\u001b[J194         0.378377    0.452594              3.06644       \n",
      "\u001b[J195         0.369576    0.462638              3.08283       \n",
      "\u001b[J196         0.359686    0.430483              3.09999       \n",
      "\u001b[J197         0.38512     0.446078              3.11537       \n",
      "\u001b[J198         0.368772    0.45653               3.13083       \n",
      "\u001b[J199         0.363822    0.430643              3.14731       \n",
      "\u001b[J200         0.366137    0.426616              3.16341       \n",
      "\u001b[J201         0.35502     0.429432              3.18131       \n",
      "\u001b[J202         0.368464    0.438965              3.19827       \n",
      "\u001b[J203         0.363739    0.446877              3.21742       \n",
      "\u001b[J204         0.375587    0.428853              3.23525       \n",
      "\u001b[J205         0.338957    0.433197              3.25236       \n",
      "\u001b[J206         0.357282    0.41585               3.27074       \n",
      "\u001b[J207         0.397092    0.448016              3.28931       \n",
      "\u001b[J208         0.291328    0.423771              3.30831       \n",
      "\u001b[J209         0.366893    0.418894              3.32545       \n",
      "\u001b[J210         0.34779     0.412874              3.34128       \n",
      "\u001b[J211         0.324196    0.442755              3.35843       \n",
      "\u001b[J212         0.368536    0.416003              3.37405       \n",
      "\u001b[J213         0.348679    0.4128                3.38946       \n",
      "\u001b[J214         0.333632    0.423161              3.40462       \n",
      "\u001b[J215         0.342228    0.413126              3.42301       \n",
      "\u001b[J216         0.339761    0.416571              3.44391       \n",
      "\u001b[J217         0.349267    0.41305               3.46134       \n",
      "\u001b[J218         0.322081    0.406516              3.47871       \n",
      "\u001b[J219         0.329394    0.414387              3.49506       \n",
      "\u001b[J220         0.351674    0.410943              3.51123       \n",
      "\u001b[J221         0.327306    0.420124              3.52874       \n",
      "\u001b[J222         0.325974    0.394888              3.54427       \n",
      "\u001b[J223         0.337033    0.399906              3.55977       \n",
      "\u001b[J224         0.334118    0.422343              3.57503       \n",
      "\u001b[J225         0.331046    0.405215              3.59012       \n",
      "\u001b[J226         0.332051    0.390239              3.6071        \n",
      "\u001b[J227         0.33377     0.401605              3.62383       \n",
      "\u001b[J228         0.31761     0.393804              3.64242       \n",
      "\u001b[J229         0.309977    0.401098              3.6623        \n",
      "\u001b[J230         0.328371    0.389832              3.67931       \n",
      "\u001b[J231         0.320131    0.387969              3.69819       \n",
      "\u001b[J232         0.30371     0.402542              3.71477       \n",
      "\u001b[J233         0.325713    0.38282               3.7313        \n",
      "\u001b[J234         0.331919    0.387318              3.74682       \n",
      "\u001b[J235         0.304323    0.396733              3.76338       \n",
      "\u001b[J236         0.30701     0.386614              3.78054       \n",
      "\u001b[J237         0.305463    0.377109              3.79643       \n",
      "\u001b[J238         0.33341     0.376344              3.8139        \n",
      "\u001b[J239         0.3033      0.38489               3.83564       \n",
      "\u001b[J240         0.311289    0.380216              3.85527       \n",
      "\u001b[J241         0.293258    0.37884               3.8763        \n",
      "\u001b[J242         0.342776    0.382962              3.8933        \n",
      "\u001b[J243         0.304284    0.399128              3.91074       \n",
      "\u001b[J244         0.299244    0.358743              3.92823       \n",
      "\u001b[J245         0.313966    0.37079               3.94434       \n",
      "\u001b[J246         0.304481    0.381231              3.96119       \n",
      "\u001b[J247         0.307172    0.367567              3.97755       \n",
      "\u001b[J248         0.283651    0.38007               3.99406       \n",
      "\u001b[J249         0.308216    0.366082              4.01065       \n",
      "\u001b[J250         0.301708    0.35979               4.02765       \n",
      "\u001b[J251         0.318256    0.373368              4.04496       \n",
      "\u001b[J252         0.299289    0.355102              4.06311       \n",
      "\u001b[J253         0.299966    0.385032              4.08302       \n",
      "\u001b[J254         0.31892     0.363715              4.10123       \n",
      "\u001b[J255         0.287568    0.36167               4.11873       \n",
      "\u001b[J256         0.317459    0.380988              4.13851       \n",
      "\u001b[J257         0.293394    0.343582              4.15548       \n",
      "\u001b[J258         0.298275    0.38686               4.17351       \n",
      "\u001b[J259         0.284708    0.362817              4.19119       \n",
      "\u001b[J260         0.293045    0.351582              4.20783       \n",
      "\u001b[J261         0.282817    0.357469              4.22587       \n",
      "\u001b[J262         0.292035    0.355452              4.24283       \n",
      "\u001b[J263         0.275535    0.345902              4.26139       \n",
      "\u001b[J264         0.289244    0.354271              4.28139       \n",
      "\u001b[J265         0.291669    0.349343              4.29992       \n",
      "\u001b[J266         0.286734    0.344604              4.31966       \n",
      "\u001b[J267         0.296139    0.375738              4.3376        \n",
      "\u001b[J268         0.27727     0.340433              4.3595        \n",
      "\u001b[J269         0.28017     0.34408               4.37848       \n",
      "\u001b[J270         0.280624    0.352704              4.39718       \n",
      "\u001b[J271         0.29958     0.34138               4.4161        \n",
      "\u001b[J272         0.265356    0.348621              4.43257       \n",
      "\u001b[J273         0.251455    0.347427              4.45161       \n",
      "\u001b[J274         0.286019    0.349018              4.46873       \n",
      "\u001b[J275         0.285064    0.333402              4.48833       \n",
      "\u001b[J276         0.281786    0.356335              4.50992       \n",
      "\u001b[J277         0.256942    0.347424              4.52821       \n",
      "\u001b[J278         0.282881    0.321016              4.54668       \n",
      "\u001b[J279         0.287412    0.36106               4.5644        \n",
      "\u001b[J280         0.271001    0.334178              4.58195       \n",
      "\u001b[J281         0.282199    0.32152               4.60056       \n",
      "\u001b[J282         0.251164    0.327614              4.61756       \n",
      "\u001b[J283         0.266823    0.328102              4.636         \n",
      "\u001b[J284         0.26775     0.339522              4.65539       \n",
      "\u001b[J285         0.271656    0.323621              4.67303       \n",
      "\u001b[J286         0.256578    0.329737              4.69405       \n",
      "\u001b[J287         0.271735    0.340108              4.71775       \n",
      "\u001b[J288         0.266488    0.322813              4.73904       \n",
      "\u001b[J289         0.259348    0.320094              4.7589        \n",
      "\u001b[J290         0.270396    0.328263              4.7777        \n",
      "\u001b[J291         0.258895    0.322638              4.79727       \n",
      "\u001b[J292         0.258122    0.344426              4.81618       \n",
      "\u001b[J293         0.275746    0.324088              4.83283       \n",
      "\u001b[J294         0.246184    0.31825               4.85118       \n",
      "\u001b[J295         0.260286    0.308677              4.86954       \n",
      "\u001b[J296         0.265393    0.31726               4.89443       \n",
      "\u001b[J297         0.241362    0.329383              4.91695       \n",
      "\u001b[J298         0.255089    0.31173               4.9364        \n",
      "\u001b[J299         0.276071    0.329865              4.95549       \n",
      "\u001b[J300         0.257054    0.324575              4.97405       \n",
      "\u001b[J301         0.266352    0.32069               4.99358       \n",
      "\u001b[J302         0.280618    0.316304              5.01135       \n",
      "\u001b[J303         0.235067    0.29685               5.03237       \n",
      "\u001b[J304         0.267568    0.313751              5.05396       \n",
      "\u001b[J305         0.247849    0.366187              5.0726        \n",
      "\u001b[J306         0.275081    0.302199              5.09471       \n",
      "\u001b[J307         0.237396    0.312898              5.11786       \n",
      "\u001b[J308         0.249253    0.303309              5.14088       \n",
      "\u001b[J309         0.234652    0.302158              5.16011       \n",
      "\u001b[J310         0.249374    0.322354              5.17919       \n",
      "\u001b[J311         0.240941    0.313066              5.19965       \n",
      "\u001b[J312         0.248661    0.306441              5.21718       \n",
      "\u001b[J313         0.250117    0.295101              5.23468       \n",
      "\u001b[J314         0.240233    0.302006              5.25511       \n",
      "\u001b[J315         0.253467    0.320684              5.27269       \n",
      "\u001b[J316         0.227645    0.309027              5.29228       \n",
      "\u001b[J317         0.265715    0.305463              5.31003       \n",
      "\u001b[J318         0.233636    0.294903              5.33          \n",
      "\u001b[J319         0.237664    0.305265              5.35053       \n",
      "\u001b[J320         0.246099    0.31427               5.36986       \n",
      "\u001b[J321         0.259953    0.297956              5.39042       \n",
      "\u001b[J322         0.226046    0.282585              5.41197       \n",
      "\u001b[J323         0.225045    0.29744               5.4328        \n",
      "\u001b[J324         0.240209    0.309028              5.45257       \n",
      "\u001b[J325         0.246721    0.294213              5.4711        \n",
      "\u001b[J326         0.236214    0.307387              5.49098       \n",
      "\u001b[J327         0.233732    0.28781               5.50903       \n",
      "\u001b[J328         0.234972    0.288172              5.5284        \n",
      "\u001b[J329         0.244626    0.297124              5.54897       \n",
      "\u001b[J330         0.228705    0.305104              5.56881       \n",
      "\u001b[J331         0.234193    0.290518              5.58942       \n",
      "\u001b[J332         0.226027    0.292374              5.60862       \n",
      "\u001b[J333         0.236416    0.280767              5.62745       \n",
      "\u001b[J334         0.231605    0.29455               5.64674       \n",
      "\u001b[J335         0.2371      0.301874              5.6664        \n",
      "\u001b[J336         0.212257    0.290251              5.68789       \n",
      "\u001b[J337         0.264117    0.293912              5.70596       \n",
      "\u001b[J338         0.21537     0.295048              5.72434       \n",
      "\u001b[J339         0.231757    0.296546              5.74331       \n",
      "\u001b[J340         0.228552    0.281754              5.76405       \n",
      "\u001b[J341         0.225486    0.285083              5.78621       \n",
      "\u001b[J342         0.233705    0.279427              5.8058        \n",
      "\u001b[J343         0.218231    0.297276              5.8249        \n",
      "\u001b[J344         0.235201    0.299268              5.84391       \n",
      "\u001b[J345         0.231026    0.267872              5.86193       \n",
      "\u001b[J346         0.21911     0.291748              5.88297       \n",
      "\u001b[J347         0.241015    0.302502              5.90157       \n",
      "\u001b[J348         0.214712    0.271311              5.92073       \n",
      "\u001b[J349         0.24142     0.277626              5.9427        \n",
      "\u001b[J350         0.221032    0.289012              5.96406       \n",
      "\u001b[J351         0.267673    0.280226              5.98948       \n",
      "\u001b[J352         0.162757    0.284835              6.01039       \n",
      "\u001b[J353         0.224687    0.279167              6.03144       \n",
      "\u001b[J354         0.246087    0.282942              6.05124       \n",
      "\u001b[J355         0.207423    0.270969              6.07204       \n",
      "\u001b[J356         0.240007    0.285128              6.09239       \n",
      "\u001b[J357         0.196085    0.291304              6.11483       \n",
      "\u001b[J358         0.218594    0.28028               6.13461       \n",
      "\u001b[J359         0.225116    0.263769              6.15401       \n",
      "\u001b[J360         0.220147    0.285674              6.17502       \n",
      "\u001b[J361         0.224147    0.272172              6.19751       \n",
      "\u001b[J362         0.19803     0.27966               6.21944       \n",
      "\u001b[J363         0.218848    0.279417              6.24087       \n",
      "\u001b[J364         0.221866    0.260744              6.26114       \n",
      "\u001b[J365         0.218713    0.271535              6.28015       \n",
      "\u001b[J366         0.208467    0.281666              6.29994       \n",
      "\u001b[J367         0.219987    0.280333              6.31855       \n",
      "\u001b[J368         0.208901    0.267368              6.33718       \n",
      "\u001b[J369         0.229474    0.267472              6.35623       \n",
      "\u001b[J370         0.203811    0.259973              6.3748        \n",
      "\u001b[J371         0.21173     0.274154              6.39572       \n",
      "\u001b[J372         0.204256    0.288347              6.41749       \n",
      "\u001b[J373         0.221526    0.268622              6.43957       \n",
      "\u001b[J374         0.205617    0.263241              6.46028       \n",
      "\u001b[J375         0.213855    0.259546              6.4841        \n",
      "\u001b[J376         0.236576    0.274457              6.50673       \n",
      "\u001b[J377         0.181113    0.264916              6.52744       \n",
      "\u001b[J378         0.208253    0.266147              6.5466        \n",
      "\u001b[J379         0.216201    0.293483              6.56606       \n",
      "\u001b[J380         0.219123    0.252879              6.58587       \n",
      "\u001b[J381         0.200094    0.281477              6.60559       \n",
      "\u001b[J382         0.221556    0.261615              6.629         \n",
      "\u001b[J383         0.210371    0.28451               6.65289       \n",
      "\u001b[J384         0.205352    0.270257              6.67463       \n",
      "\u001b[J385         0.210777    0.257561              6.69548       \n",
      "\u001b[J386         0.202188    0.254426              6.71609       \n",
      "\u001b[J387         0.200691    0.271721              6.73705       \n",
      "\u001b[J388         0.219962    0.26262               6.75616       \n",
      "\u001b[J389         0.205825    0.25115               6.77586       \n",
      "\u001b[J390         0.186607    0.258145              6.79584       \n",
      "\u001b[J391         0.184955    0.25919               6.81587       \n",
      "\u001b[J392         0.211982    0.261205              6.83658       \n",
      "\u001b[J393         0.213651    0.270069              6.85975       \n",
      "\u001b[J394         0.218271    0.253798              6.88105       \n",
      "\u001b[J395         0.202618    0.243478              6.9016        \n",
      "\u001b[J396         0.187163    0.272486              6.92273       \n",
      "\u001b[J397         0.211315    0.255492              6.94263       \n",
      "\u001b[J398         0.197162    0.262523              6.96255       \n",
      "\u001b[J399         0.209669    0.271295              6.98214       \n",
      "\u001b[J400         0.203969    0.24593               7.00555       \n",
      "\u001b[J401         0.1888      0.282057              7.0291        \n",
      "\u001b[J402         0.204638    0.253193              7.0531        \n",
      "\u001b[J403         0.207561    0.251405              7.07752       \n",
      "\u001b[J404         0.188855    0.249149              7.09838       \n",
      "\u001b[J405         0.199377    0.261278              7.12199       \n",
      "\u001b[J406         0.204509    0.26634               7.14439       \n",
      "\u001b[J407         0.178979    0.235112              7.16624       \n",
      "\u001b[J408         0.197585    0.245864              7.18699       \n",
      "\u001b[J409         0.201479    0.265315              7.20806       \n",
      "\u001b[J410         0.192346    0.256825              7.22844       \n",
      "\u001b[J411         0.189591    0.274905              7.25139       \n",
      "\u001b[J412         0.186871    0.241233              7.27467       \n",
      "\u001b[J413         0.203923    0.249144              7.29709       \n",
      "\u001b[J414         0.197907    0.269648              7.31908       \n",
      "\u001b[J415         0.206384    0.235739              7.34278       \n",
      "\u001b[J416         0.196257    0.272834              7.36422       \n",
      "\u001b[J417         0.186111    0.242634              7.38384       \n",
      "\u001b[J418         0.197527    0.249405              7.40397       \n",
      "\u001b[J419         0.187723    0.265485              7.42379       \n",
      "\u001b[J420         0.191652    0.258141              7.44425       \n",
      "\u001b[J421         0.181423    0.233506              7.4649        \n",
      "\u001b[J422         0.18184     0.237864              7.48767       \n",
      "\u001b[J423         0.20759     0.25824               7.51286       \n",
      "\u001b[J424         0.188459    0.270502              7.54067       \n",
      "\u001b[J425         0.194089    0.238649              7.56321       \n",
      "\u001b[J426         0.174289    0.236303              7.58583       \n",
      "\u001b[J427         0.192545    0.261223              7.60662       \n",
      "\u001b[J428         0.197349    0.241519              7.6279        \n",
      "\u001b[J429         0.206949    0.239263              7.64955       \n",
      "\u001b[J430         0.211763    0.275525              7.67217       \n",
      "\u001b[J431         0.215159    0.252556              7.69569       \n",
      "\u001b[J432         0.155853    0.261587              7.7194        \n",
      "\u001b[J433         0.182906    0.231365              7.74477       \n",
      "\u001b[J434         0.207902    0.234157              7.76586       \n",
      "\u001b[J435         0.180148    0.276776              7.78655       \n",
      "\u001b[J436         0.181362    0.2378                7.8083        \n",
      "\u001b[J437         0.199468    0.22872               7.82865       \n",
      "\u001b[J438         0.185824    0.22976               7.8489        \n",
      "\u001b[J439         0.174341    0.248284              7.87059       \n",
      "\u001b[J440         0.1755      0.25693               7.89287       \n",
      "\u001b[J441         0.182659    0.255348              7.91812       \n",
      "\u001b[J442         0.203197    0.240873              7.94058       \n",
      "\u001b[J443         0.164776    0.236297              7.965         \n",
      "\u001b[J444         0.185183    0.239875              7.98641       \n",
      "\u001b[J445         0.185575    0.218554              8.00745       \n",
      "\u001b[J446         0.174318    0.24972               8.03003       \n",
      "\u001b[J447         0.19061     0.25294               8.05192       \n",
      "\u001b[J448         0.172913    0.245736              8.07747       \n",
      "\u001b[J449         0.182246    0.231173              8.09903       \n",
      "\u001b[J450         0.182934    0.234421              8.12249       \n",
      "\u001b[J451         0.168193    0.254925              8.1509        \n",
      "\u001b[J452         0.18085     0.240712              8.1743        \n",
      "\u001b[J453         0.192271    0.222569              8.19693       \n",
      "\u001b[J454         0.166773    0.247219              8.21946       \n",
      "\u001b[J455         0.182334    0.246722              8.24177       \n",
      "\u001b[J456         0.164506    0.24122               8.26375       \n",
      "\u001b[J457         0.217982    0.23306               8.28517       \n",
      "\u001b[J458         0.177278    0.233428              8.30632       \n",
      "\u001b[J459         0.147808    0.240461              8.33155       \n",
      "\u001b[J460         0.173022    0.235193              8.35565       \n",
      "\u001b[J461         0.184134    0.235316              8.38026       \n",
      "\u001b[J462         0.169659    0.230663              8.40325       \n",
      "\u001b[J463         0.177591    0.222627              8.42465       \n",
      "\u001b[J464         0.169216    0.25203               8.44778       \n",
      "\u001b[J465         0.177223    0.257868              8.46886       \n",
      "\u001b[J466         0.168244    0.214187              8.49165       \n",
      "\u001b[J467         0.188875    0.226968              8.51282       \n",
      "\u001b[J468         0.164689    0.253412              8.53576       \n",
      "\u001b[J469         0.175029    0.239243              8.56054       \n",
      "\u001b[J470         0.175582    0.22621               8.58455       \n",
      "\u001b[J471         0.192021    0.230625              8.6116        \n",
      "\u001b[J472         0.129708    0.231772              8.63547       \n",
      "\u001b[J473         0.195712    0.215792              8.65899       \n",
      "\u001b[J474         0.159929    0.23952               8.68184       \n",
      "\u001b[J475         0.165227    0.235845              8.70324       \n",
      "\u001b[J476         0.16863     0.229651              8.72608       \n",
      "\u001b[J477         0.206113    0.230162              8.75163       \n",
      "\u001b[J478         0.13072     0.235044              8.77575       \n",
      "\u001b[J479         0.179023    0.230165              8.79844       \n",
      "\u001b[J480         0.163873    0.238625              8.82092       \n",
      "\u001b[J481         0.16144     0.224333              8.8444        \n",
      "\u001b[J482         0.167659    0.231062              8.86682       \n",
      "\u001b[J483         0.177118    0.232476              8.88856       \n",
      "\u001b[J484         0.163036    0.242504              8.9143        \n",
      "\u001b[J485         0.170238    0.229804              8.93624       \n",
      "\u001b[J486         0.181368    0.223593              8.96114       \n",
      "\u001b[J487         0.144464    0.219653              8.9859        \n",
      "\u001b[J488         0.184249    0.230097              9.00878       \n",
      "\u001b[J489         0.140666    0.236579              9.03184       \n",
      "\u001b[J490         0.168419    0.230858              9.05345       \n",
      "\u001b[J491         0.163384    0.225769              9.07676       \n",
      "\u001b[J492         0.15059     0.223323              9.09858       \n",
      "\u001b[J493         0.181916    0.22387               9.1231        \n",
      "\u001b[J494         0.160323    0.219625              9.14906       \n",
      "\u001b[J495         0.155968    0.213019              9.17638       \n",
      "\u001b[J496         0.156117    0.246445              9.20379       \n",
      "\u001b[J497         0.165235    0.239182              9.2279        \n",
      "\u001b[J498         0.171457    0.213569              9.25089       \n",
      "\u001b[J499         0.1583      0.222379              9.27287       \n",
      "\u001b[J500         0.165213    0.234654              9.30139       \n",
      "\u001b[J501         0.173817    0.21082               9.3252        \n",
      "\u001b[J502         0.14878     0.211656              9.35079       \n",
      "\u001b[J503         0.15606     0.244544              9.37378       \n",
      "\u001b[J504         0.168516    0.249653              9.39894       \n",
      "\u001b[J505         0.152217    0.211014              9.42337       \n",
      "\u001b[J506         0.151616    0.210772              9.44806       \n",
      "\u001b[J507         0.169704    0.232275              9.47006       \n",
      "\u001b[J508         0.151522    0.224862              9.49323       \n",
      "\u001b[J509         0.175072    0.231325              9.51491       \n",
      "\u001b[J510         0.148514    0.216168              9.53779       \n",
      "\u001b[J511         0.142685    0.20906               9.56201       \n",
      "\u001b[J512         0.162187    0.226221              9.58394       \n",
      "\u001b[J513         0.168295    0.223889              9.60903       \n",
      "\u001b[J514         0.160064    0.223824              9.63663       \n",
      "\u001b[J515         0.155841    0.203918              9.66489       \n",
      "\u001b[J516         0.155524    0.227446              9.6916        \n",
      "\u001b[J517         0.162192    0.256447              9.71562       \n",
      "\u001b[J518         0.157976    0.209688              9.73806       \n",
      "\u001b[J519         0.156079    0.213985              9.76175       \n",
      "\u001b[J520         0.155326    0.213821              9.78563       \n",
      "\u001b[J521         0.151867    0.22712               9.81109       \n",
      "\u001b[J522         0.172366    0.215359              9.83629       \n",
      "\u001b[J523         0.145759    0.228196              9.8614        \n",
      "\u001b[J524         0.154594    0.218241              9.88474       \n",
      "\u001b[J525         0.153584    0.212399              9.90727       \n",
      "\u001b[J526         0.160136    0.239436              9.93398       \n",
      "\u001b[J527         0.139929    0.243962              9.95899       \n",
      "\u001b[J528         0.17139     0.192321              9.98142       \n",
      "\u001b[J529         0.144108    0.227638              10.0088       \n",
      "\u001b[J530         0.162087    0.224066              10.0358       \n",
      "\u001b[J531         0.154481    0.214766              10.0622       \n",
      "\u001b[J532         0.148638    0.225576              10.085        \n",
      "\u001b[J533         0.141184    0.226849              10.1078       \n",
      "\u001b[J534         0.154841    0.206759              10.1328       \n",
      "\u001b[J535         0.14784     0.202188              10.1587       \n",
      "\u001b[J536         0.136321    0.217484              10.1887       \n",
      "\u001b[J537         0.165095    0.224857              10.2141       \n",
      "\u001b[J538         0.147513    0.244813              10.2395       \n",
      "\u001b[J539         0.154911    0.21855               10.2662       \n",
      "\u001b[J540         0.172646    0.199516              10.2908       \n",
      "\u001b[J541         0.15508     0.266788              10.3161       \n",
      "\u001b[J542         0.14236     0.206288              10.3437       \n",
      "\u001b[J543         0.166711    0.202843              10.3668       \n",
      "\u001b[J544         0.135278    0.23961               10.3909       \n",
      "\u001b[J545         0.156362    0.217334              10.4192       \n",
      "\u001b[J546         0.13773     0.213343              10.446        \n",
      "\u001b[J547         0.162629    0.224794              10.4739       \n",
      "\u001b[J548         0.137834    0.202768              10.4984       \n",
      "\u001b[J549         0.152838    0.216274              10.5233       \n",
      "\u001b[J550         0.145231    0.205706              10.5496       \n",
      "\u001b[J551         0.143841    0.231592              10.5733       \n",
      "\u001b[J552         0.177344    0.230746              10.5975       \n",
      "\u001b[J553         0.139247    0.176972              10.6214       \n",
      "\u001b[J554         0.150924    0.199057              10.6475       \n",
      "\u001b[J555         0.147664    0.267243              10.6775       \n",
      "\u001b[J556         0.152257    0.212413              10.7072       \n",
      "\u001b[J557         0.143603    0.216819              10.7355       \n",
      "\u001b[J558         0.134814    0.204239              10.7603       \n",
      "\u001b[J559         0.143374    0.198281              10.7854       \n",
      "\u001b[J560         0.141237    0.211052              10.8105       \n",
      "\u001b[J561         0.141455    0.225124              10.836        \n",
      "\u001b[J562         0.137044    0.215198              10.8636       \n",
      "\u001b[J563         0.143373    0.215193              10.8901       \n",
      "\u001b[J564         0.147107    0.199922              10.914        \n",
      "\u001b[J565         0.143057    0.203597              10.9404       \n",
      "\u001b[J566         0.163417    0.246647              10.9656       \n",
      "\u001b[J567         0.117002    0.20209               10.989        \n",
      "\u001b[J568         0.145841    0.198285              11.0138       \n",
      "\u001b[J569         0.138426    0.234451              11.0383       \n",
      "\u001b[J570         0.150942    0.214                 11.0634       \n",
      "\u001b[J571         0.151544    0.206631              11.0913       \n",
      "\u001b[J572         0.152612    0.178166              11.1164       \n",
      "\u001b[J573         0.16377     0.225131              11.1425       \n",
      "\u001b[J574         0.108199    0.233716              11.1679       \n",
      "\u001b[J575         0.141865    0.218825              11.1958       \n",
      "\u001b[J576         0.13705     0.192212              11.2214       \n",
      "\u001b[J577         0.129699    0.200248              11.2501       \n",
      "\u001b[J578         0.138312    0.198502              11.2773       \n",
      "\u001b[J579         0.141825    0.217664              11.3052       \n",
      "\u001b[J580         0.138956    0.214658              11.3305       \n",
      "\u001b[J581         0.127249    0.201159              11.3571       \n",
      "\u001b[J582         0.14434     0.201107              11.3817       \n",
      "\u001b[J583         0.136901    0.208274              11.4079       \n",
      "\u001b[J584         0.13425     0.219101              11.4344       \n",
      "\u001b[J585         0.145994    0.232102              11.4609       \n",
      "\u001b[J586         0.137171    0.181714              11.4873       \n",
      "\u001b[J587         0.133856    0.197946              11.5146       \n",
      "\u001b[J588         0.143301    0.244453              11.54         \n",
      "\u001b[J589         0.147126    0.220064              11.5654       \n",
      "\u001b[J590         0.13466     0.186782              11.5898       \n",
      "\u001b[J591         0.156663    0.187529              11.6155       \n",
      "\u001b[J592         0.109521    0.233829              11.6411       \n",
      "\u001b[J593         0.171402    0.234524              11.6664       \n",
      "\u001b[J594         0.108476    0.201012              11.6944       \n",
      "\u001b[J595         0.144146    0.174109              11.7207       \n",
      "\u001b[J596         0.125294    0.2275                11.7491       \n",
      "\u001b[J597         0.131938    0.228935              11.7773       \n",
      "\u001b[J598         0.142095    0.195233              11.8046       \n",
      "\u001b[J599         0.138637    0.199227              11.8321       \n",
      "\u001b[J600         0.139483    0.214895              11.8569       \n",
      "\u001b[J601         0.122545    0.207077              11.8832       \n",
      "\u001b[J602         0.144094    0.195764              11.9096       \n",
      "\u001b[J603         0.140678    0.221786              11.9365       \n",
      "\u001b[J604         0.12493     0.19037               11.966        \n",
      "\u001b[J605         0.12882     0.202167              11.9906       \n",
      "\u001b[J606         0.120323    0.221168              12.0175       \n",
      "\u001b[J607         0.139906    0.198411              12.0438       \n",
      "\u001b[J608         0.140095    0.179942              12.0676       \n",
      "\u001b[J609         0.12243     0.197233              12.0958       \n",
      "\u001b[J610         0.136098    0.238881              12.1221       \n",
      "\u001b[J611         0.152522    0.197919              12.1532       \n",
      "\u001b[J612         0.111863    0.185419              12.1793       \n",
      "\u001b[J613         0.137076    0.210443              12.2049       \n",
      "\u001b[J614         0.135995    0.195092              12.23         \n",
      "\u001b[J615         0.130074    0.243657              12.2588       \n",
      "\u001b[J616         0.121323    0.196429              12.286        \n",
      "\u001b[J617         0.139091    0.209114              12.316        \n",
      "\u001b[J618         0.116504    0.200599              12.3468       \n",
      "\u001b[J619         0.133709    0.207643              12.3749       \n",
      "\u001b[J620         0.131401    0.190229              12.4048       \n",
      "\u001b[J621         0.127754    0.227424              12.4337       \n",
      "\u001b[J622         0.141025    0.197907              12.4589       \n",
      "\u001b[J623         0.104282    0.182052              12.4841       \n",
      "\u001b[J624         0.129663    0.207474              12.509        \n",
      "\u001b[J625         0.126047    0.209698              12.534        \n",
      "\u001b[J626         0.127341    0.191585              12.5628       \n",
      "\u001b[J627         0.122834    0.187427              12.5899       \n",
      "\u001b[J628         0.135127    0.23276               12.6173       \n",
      "\u001b[J629         0.116247    0.211375              12.6433       \n",
      "\u001b[J630         0.129122    0.196509              12.6712       \n",
      "\u001b[J631         0.120726    0.197063              12.6977       \n",
      "\u001b[J632         0.121697    0.207617              12.722        \n",
      "\u001b[J633         0.124398    0.191519              12.7512       \n",
      "\u001b[J634         0.122302    0.205701              12.7775       \n",
      "\u001b[J635         0.124378    0.210426              12.8056       \n",
      "\u001b[J636         0.12066     0.21122               12.8378       \n",
      "\u001b[J637         0.125007    0.225453              12.8675       \n",
      "\u001b[J638         0.124155    0.189892              12.8948       \n",
      "\u001b[J639         0.125526    0.204007              12.9194       \n",
      "\u001b[J640         0.121586    0.212516              12.9453       \n",
      "\u001b[J641         0.128615    0.188681              12.974        \n",
      "\u001b[J642         0.134307    0.208283              13.0024       \n",
      "\u001b[J643         0.121185    0.201791              13.0319       \n",
      "\u001b[J644         0.101854    0.19764               13.0592       \n",
      "\u001b[J645         0.116875    0.215951              13.0847       \n",
      "\u001b[J646         0.115649    0.202208              13.1118       \n",
      "\u001b[J647         0.143721    0.183307              13.1385       \n",
      "\u001b[J648         0.0941086   0.202221              13.1685       \n",
      "\u001b[J649         0.129479    0.230566              13.1991       \n",
      "\u001b[J650         0.120421    0.189999              13.2286       \n",
      "\u001b[J651         0.10969     0.18664               13.2576       \n",
      "\u001b[J652         0.116351    0.193086              13.2843       \n",
      "\u001b[J653         0.133944    0.226354              13.3105       \n",
      "\u001b[J654         0.114916    0.204813              13.3363       \n",
      "\u001b[J655         0.144888    0.160229              13.3664       \n",
      "\u001b[J656         0.13334     0.235489              13.3963       \n",
      "\u001b[J657         0.0929252   0.228618              13.4235       \n",
      "\u001b[J658         0.11966     0.190649              13.4534       \n",
      "\u001b[J659         0.12317     0.186591              13.4813       \n",
      "\u001b[J660         0.115185    0.214068              13.5081       \n",
      "\u001b[J661         0.104463    0.19548               13.535        \n",
      "\u001b[J662         0.115644    0.201423              13.5638       \n",
      "\u001b[J663         0.118157    0.202164              13.5892       \n",
      "\u001b[J664         0.11776     0.208779              13.6148       \n",
      "\u001b[J665         0.124119    0.180235              13.6456       \n",
      "\u001b[J666         0.105005    0.205453              13.6774       \n",
      "\u001b[J667         0.127628    0.209299              13.705        \n",
      "\u001b[J668         0.109859    0.218078              13.7317       \n",
      "\u001b[J669         0.129974    0.18757               13.7573       \n",
      "\u001b[J670         0.114546    0.198165              13.784        \n",
      "\u001b[J671         0.105607    0.250773              13.8111       \n",
      "\u001b[J672         0.133081    0.206475              13.8373       \n",
      "\u001b[J673         0.120293    0.208254              13.864        \n",
      "\u001b[J674         0.114064    0.206064              13.8953       \n",
      "\u001b[J675         0.118904    0.175151              13.9289       \n",
      "\u001b[J676         0.122105    0.190459              13.9577       \n",
      "\u001b[J677         0.110835    0.203931              13.9841       \n",
      "\u001b[J678         0.0959313   0.208111              14.0121       \n",
      "\u001b[J679         0.116629    0.215689              14.0419       \n",
      "\u001b[J680         0.112081    0.181199              14.0681       \n",
      "\u001b[J681         0.10644     0.185179              14.097        \n",
      "\u001b[J682         0.111273    0.212246              14.1258       \n",
      "\u001b[J683         0.128171    0.222711              14.1559       \n",
      "\u001b[J684         0.103104    0.163809              14.1844       \n",
      "\u001b[J685         0.117949    0.192816              14.2109       \n",
      "\u001b[J686         0.104053    0.217                 14.2383       \n",
      "\u001b[J687         0.112133    0.202962              14.264        \n",
      "\u001b[J688         0.112264    0.18746               14.2922       \n",
      "\u001b[J689         0.131884    0.199459              14.324        \n",
      "\u001b[J690         0.0953037   0.187516              14.3543       \n",
      "\u001b[J691         0.117437    0.219237              14.3829       \n",
      "\u001b[J692         0.0956144   0.201852              14.4123       \n",
      "\u001b[J693         0.110964    0.191561              14.4436       \n",
      "\u001b[J694         0.115607    0.177833              14.4711       \n",
      "\u001b[J695         0.111045    0.213155              14.4985       \n",
      "\u001b[J696         0.116555    0.207786              14.5284       \n",
      "\u001b[J697         0.107632    0.189454              14.558        \n",
      "\u001b[J698         0.117795    0.217823              14.5862       \n",
      "\u001b[J699         0.105315    0.199253              14.6154       \n",
      "\u001b[J700         0.107584    0.189043              14.646        \n",
      "\u001b[J701         0.103483    0.185174              14.6752       \n",
      "\u001b[J702         0.10668     0.204205              14.7024       \n",
      "\u001b[J703         0.110117    0.186913              14.7312       \n",
      "\u001b[J704         0.102353    0.199609              14.7616       \n",
      "\u001b[J705         0.107079    0.203927              14.7894       \n",
      "\u001b[J706         0.11195     0.202407              14.8211       \n",
      "\u001b[J707         0.0929426   0.194537              14.8502       \n",
      "\u001b[J708         0.101748    0.180648              14.8791       \n",
      "\u001b[J709         0.114971    0.194867              14.9066       \n",
      "\u001b[J710         0.104783    0.190021              14.9342       \n",
      "\u001b[J711         0.119076    0.204946              14.9704       \n",
      "\u001b[J712         0.110107    0.18734               15.0009       \n",
      "\u001b[J713         0.0886319   0.208534              15.032        \n",
      "\u001b[J714         0.110793    0.209448              15.059        \n",
      "\u001b[J715         0.100784    0.190238              15.0881       \n",
      "\u001b[J716         0.113679    0.17164               15.1166       \n",
      "\u001b[J717         0.0882213   0.241648              15.1468       \n",
      "\u001b[J718         0.110983    0.224273              15.1795       \n",
      "\u001b[J719         0.106331    0.191099              15.2075       \n",
      "\u001b[J720         0.103305    0.178625              15.2386       \n",
      "\u001b[J721         0.100186    0.192163              15.2673       \n",
      "\u001b[J722         0.109744    0.225552              15.2959       \n",
      "\u001b[J723         0.104814    0.183068              15.3226       \n",
      "\u001b[J724         0.100517    0.21584               15.3519       \n",
      "\u001b[J725         0.112304    0.194999              15.383        \n",
      "\u001b[J726         0.113976    0.19854               15.4133       \n",
      "\u001b[J727         0.0952671   0.209144              15.4435       \n",
      "\u001b[J728         0.102742    0.183182              15.4713       \n",
      "\u001b[J729         0.10704     0.185262              15.5027       \n",
      "\u001b[J730         0.106209    0.210319              15.5315       \n",
      "\u001b[J731         0.0996663   0.195302              15.5621       \n",
      "\u001b[J732         0.0943933   0.20429               15.593        \n",
      "\u001b[J733         0.107579    0.193063              15.6223       \n",
      "\u001b[J734         0.0965645   0.18404               15.6518       \n",
      "\u001b[J735         0.110412    0.180701              15.6811       \n",
      "\u001b[J736         0.0948138   0.236155              15.7093       \n",
      "\u001b[J737         0.103111    0.186892              15.7384       \n",
      "\u001b[J738         0.119913    0.206026              15.7682       \n",
      "\u001b[J739         0.0886025   0.182718              15.8021       \n",
      "\u001b[J740         0.104743    0.177742              15.8313       \n",
      "\u001b[J741         0.0907515   0.220611              15.8634       \n",
      "\u001b[J742         0.124828    0.225762              15.8908       \n",
      "\u001b[J743         0.101004    0.176644              15.9191       \n",
      "\u001b[J744         0.0969532   0.184244              15.946        \n",
      "\u001b[J745         0.105594    0.231607              15.9786       \n",
      "\u001b[J746         0.0978567   0.1871                16.0165       \n",
      "\u001b[J747         0.106479    0.222698              16.049        \n",
      "\u001b[J748         0.102698    0.184017              16.0779       \n",
      "\u001b[J749         0.109722    0.179547              16.1068       \n",
      "\u001b[J750         0.092573    0.256189              16.1364       \n",
      "\u001b[J751         0.0953923   0.186287              16.1709       \n",
      "\u001b[J752         0.107316    0.19787               16.2009       \n",
      "\u001b[J753         0.130119    0.219288              16.2322       \n",
      "\u001b[J754         0.0769495   0.169698              16.2614       \n",
      "\u001b[J755         0.0967058   0.198163              16.2896       \n",
      "\u001b[J756         0.0885993   0.206495              16.3191       \n",
      "\u001b[J757         0.114111    0.209305              16.3496       \n",
      "\u001b[J758         0.0879287   0.175948              16.3776       \n",
      "\u001b[J759         0.100242    0.182548              16.4071       \n",
      "\u001b[J760         0.101393    0.221163              16.439        \n",
      "\u001b[J761         0.0922152   0.19811               16.4701       \n",
      "\u001b[J762         0.101042    0.201859              16.4994       \n",
      "\u001b[J763         0.0941979   0.193091              16.5324       \n",
      "\u001b[J764         0.0970523   0.201933              16.5645       \n",
      "\u001b[J765         0.10004     0.201586              16.5936       \n",
      "\u001b[J766         0.0875916   0.187299              16.6245       \n",
      "\u001b[J767         0.11639     0.195626              16.6582       \n",
      "\u001b[J768         0.097209    0.229858              16.6889       \n",
      "\u001b[J769         0.13139     0.164066              16.7168       \n",
      "\u001b[J770         0.0947413   0.264022              16.745        \n",
      "\u001b[J771         0.0905734   0.199483              16.7749       \n",
      "\u001b[J772         0.119708    0.223411              16.8032       \n",
      "\u001b[J773         0.091968    0.171035              16.8333       \n",
      "\u001b[J774         0.0987996   0.189239              16.8653       \n",
      "\u001b[J775         0.0950741   0.191518              16.8949       \n",
      "\u001b[J776         0.095309    0.199546              16.925        \n",
      "\u001b[J777         0.0941392   0.171046              16.9538       \n",
      "\u001b[J778         0.0957452   0.213739              16.9822       \n",
      "\u001b[J779         0.0925266   0.200812              17.0105       \n",
      "\u001b[J780         0.097301    0.186183              17.0415       \n",
      "\u001b[J781         0.0856894   0.234237              17.0871       \n",
      "\u001b[J782         0.0943471   0.185988              17.1204       \n",
      "\u001b[J783         0.100944    0.173323              17.1516       \n",
      "\u001b[J784         0.0949088   0.231473              17.184        \n",
      "\u001b[J785         0.0941744   0.187281              17.2147       \n",
      "\u001b[J786         0.106048    0.192751              17.2461       \n",
      "\u001b[J787         0.0691334   0.202241              17.2786       \n",
      "\u001b[J788         0.0977145   0.193161              17.3085       \n",
      "\u001b[J789         0.096535    0.18858               17.343        \n",
      "\u001b[J790         0.0922091   0.211321              17.3746       \n",
      "\u001b[J791         0.101915    0.20508               17.4046       \n",
      "\u001b[J792         0.0842869   0.209581              17.4327       \n",
      "\u001b[J793         0.0914603   0.200209              17.4645       \n",
      "\u001b[J794         0.117748    0.171456              17.497        \n",
      "\u001b[J795         0.0657459   0.224734              17.5295       \n",
      "\u001b[J796         0.0931626   0.206618              17.5592       \n",
      "\u001b[J797         0.0831162   0.180505              17.5886       \n",
      "\u001b[J798         0.0897896   0.197191              17.6222       \n",
      "\u001b[J799         0.093994    0.21438               17.654        \n",
      "\u001b[J800         0.0930489   0.172449              17.6878       \n",
      "\u001b[J801         0.08695     0.215295              17.7205       \n",
      "\u001b[J802         0.099279    0.198993              17.7503       \n",
      "\u001b[J803         0.0974051   0.214856              17.7801       \n",
      "\u001b[J804         0.0879929   0.172645              17.8091       \n",
      "\u001b[J805         0.0926736   0.171686              17.8419       \n",
      "\u001b[J806         0.0871229   0.219877              17.872        \n",
      "\u001b[J807         0.0932814   0.196663              17.9022       \n",
      "\u001b[J808         0.0867467   0.177127              17.9348       \n",
      "\u001b[J809         0.0891877   0.214636              17.965        \n",
      "\u001b[J810         0.0932937   0.194838              17.9946       \n",
      "\u001b[J811         0.0940269   0.184755              18.0249       \n",
      "\u001b[J812         0.0979784   0.240476              18.0545       \n",
      "\u001b[J813         0.0985021   0.193722              18.0843       \n",
      "\u001b[J814         0.094164    0.198069              18.1148       \n",
      "\u001b[J815         0.0874952   0.183988              18.1552       \n",
      "\u001b[J816         0.0810432   0.201118              18.1895       \n",
      "\u001b[J817         0.0927291   0.186029              18.2202       \n",
      "\u001b[J818         0.0883642   0.201401              18.2534       \n",
      "\u001b[J819         0.0892148   0.210749              18.2837       \n",
      "\u001b[J820         0.0892107   0.197023              18.3159       \n",
      "\u001b[J821         0.0854112   0.187091              18.3524       \n",
      "\u001b[J822         0.0844339   0.196041              18.3836       \n",
      "\u001b[J823         0.0907694   0.194054              18.4168       \n",
      "\u001b[J824         0.0814034   0.212225              18.4467       \n",
      "\u001b[J825         0.0940173   0.202509              18.4758       \n",
      "\u001b[J826         0.0863443   0.197475              18.5067       \n",
      "\u001b[J827         0.0906573   0.201446              18.5377       \n",
      "\u001b[J828         0.0958354   0.258518              18.5717       \n",
      "\u001b[J829         0.0828239   0.187692              18.6038       \n",
      "\u001b[J830         0.10389     0.169233              18.6351       \n",
      "\u001b[J831         0.0935693   0.226568              18.6722       \n",
      "\u001b[J832         0.0889774   0.191347              18.7045       \n",
      "\u001b[J833         0.093603    0.225554              18.7338       \n",
      "\u001b[J834         0.0929153   0.22117               18.7693       \n",
      "\u001b[J835         0.0970894   0.208223              18.8033       \n",
      "\u001b[J836         0.0872383   0.214961              18.8357       \n",
      "\u001b[J837         0.0981351   0.196596              18.8655       \n",
      "\u001b[J838         0.0802372   0.18442               18.8962       \n",
      "\u001b[J839         0.0794919   0.209482              18.927        \n",
      "\u001b[J840         0.0913554   0.196896              18.9566       \n",
      "\u001b[J841         0.0777279   0.21486               18.9914       \n",
      "\u001b[J842         0.0850933   0.183524              19.0229       \n",
      "\u001b[J843         0.0991857   0.221352              19.0579       \n",
      "\u001b[J844         0.0831719   0.173881              19.0916       \n",
      "\u001b[J845         0.0914948   0.193441              19.1233       \n",
      "\u001b[J846         0.0780586   0.266443              19.1558       \n",
      "\u001b[J847         0.0942492   0.177768              19.1871       \n",
      "\u001b[J848         0.0996623   0.183978              19.2225       \n",
      "\u001b[J849         0.0815534   0.23194               19.2567       \n",
      "\u001b[J850         0.0885686   0.189199              19.2882       \n",
      "\u001b[J851         0.078705    0.208599              19.3203       \n",
      "\u001b[J852         0.0857767   0.195532              19.3497       \n",
      "\u001b[J853         0.085237    0.222804              19.3789       \n",
      "\u001b[J854         0.0900215   0.20653               19.4091       \n",
      "\u001b[J855         0.081758    0.187639              19.4389       \n",
      "\u001b[J856         0.0893583   0.214257              19.4713       \n",
      "\u001b[J857         0.0733955   0.17933               19.5048       \n",
      "\u001b[J858         0.0886934   0.176416              19.5356       \n",
      "\u001b[J859         0.0853084   0.227142              19.5649       \n",
      "\u001b[J860         0.0826074   0.221627              19.596        \n",
      "\u001b[J861         0.0823168   0.171886              19.6279       \n",
      "\u001b[J862         0.0946331   0.212646              19.6605       \n",
      "\u001b[J863         0.0858653   0.204464              19.6964       \n",
      "\u001b[J864         0.0843461   0.183533              19.7343       \n",
      "\u001b[J865         0.0902248   0.195485              19.766        \n",
      "\u001b[J866         0.0774355   0.209953              19.7992       \n",
      "\u001b[J867         0.0842158   0.206336              19.8292       \n",
      "\u001b[J868         0.0845523   0.198303              19.8622       \n",
      "\u001b[J869         0.0983771   0.175779              19.8974       \n",
      "\u001b[J870         0.0664215   0.214309              19.9314       \n",
      "\u001b[J871         0.0801788   0.1905                19.9649       \n",
      "\u001b[J872         0.0864303   0.195768              19.9948       \n",
      "\u001b[J873         0.0791743   0.234468              20.0251       \n",
      "\u001b[J874         0.0776961   0.182859              20.06         \n",
      "\u001b[J875         0.0803955   0.181312              20.0906       \n",
      "\u001b[J876         0.0779226   0.226773              20.1229       \n",
      "\u001b[J877         0.0876517   0.183481              20.1569       \n",
      "\u001b[J878         0.0805347   0.185071              20.1926       \n",
      "\u001b[J879         0.0861847   0.221094              20.2277       \n",
      "\u001b[J880         0.0815641   0.196505              20.2664       \n",
      "\u001b[J881         0.0856831   0.199193              20.3006       \n",
      "\u001b[J882         0.0692362   0.21941               20.3317       \n",
      "\u001b[J883         0.0916052   0.210421              20.3646       \n",
      "\u001b[J884         0.0788634   0.178274              20.399        \n",
      "\u001b[J885         0.0830781   0.190657              20.4304       \n",
      "\u001b[J886         0.0791684   0.23617               20.4627       \n",
      "\u001b[J887         0.0777797   0.195072              20.494        \n",
      "\u001b[J888         0.0774051   0.17576               20.5253       \n",
      "\u001b[J889         0.0950143   0.260554              20.5584       \n",
      "\u001b[J890         0.0835777   0.187241              20.5916       \n",
      "\u001b[J891         0.0801145   0.214111              20.6262       \n",
      "\u001b[J892         0.08291     0.202278              20.6584       \n",
      "\u001b[J893         0.0809466   0.187166              20.6906       \n",
      "\u001b[J894         0.0823058   0.204923              20.7217       \n",
      "\u001b[J895         0.0773362   0.192266              20.7537       \n",
      "\u001b[J896         0.0726105   0.216616              20.7923       \n",
      "\u001b[J897         0.0855987   0.201282              20.8289       \n",
      "\u001b[J898         0.0816541   0.216937              20.863        \n",
      "\u001b[J899         0.0806084   0.209404              20.8977       \n",
      "\u001b[J900         0.0899861   0.177957              20.9288       \n",
      "\u001b[J901         0.0763648   0.23505               20.9608       \n",
      "\u001b[J902         0.0853237   0.208647              20.9914       \n",
      "\u001b[J903         0.0768471   0.195493              21.0274       \n",
      "\u001b[J904         0.0824646   0.191629              21.063        \n",
      "\u001b[J905         0.0795837   0.199347              21.0964       \n",
      "\u001b[J906         0.0810561   0.226396              21.1281       \n",
      "\u001b[J907         0.0734006   0.241234              21.164        \n",
      "\u001b[J908         0.110701    0.160862              21.1967       \n",
      "\u001b[J909         0.120839    0.202732              21.2281       \n",
      "\u001b[J910         0.0981102   0.301459              21.26         \n",
      "\u001b[J911         0.0712948   0.172938              21.2984       \n",
      "\u001b[J912         0.106514    0.255033              21.3363       \n",
      "\u001b[J913         0.103955    0.200484              21.3701       \n",
      "\u001b[J914         0.0866288   0.176501              21.4029       \n",
      "\u001b[J915         0.0950427   0.258585              21.4353       \n",
      "\u001b[J916         0.0746324   0.199691              21.4702       \n",
      "\u001b[J917         0.116219    0.174553              21.5029       \n",
      "\u001b[J918         0.0540026   0.278955              21.5387       \n",
      "\u001b[J919         0.0825818   0.195321              21.5714       \n",
      "\u001b[J920         0.0912716   0.182566              21.6044       \n",
      "\u001b[J921         0.0897261   0.239462              21.6409       \n",
      "\u001b[J922         0.0803858   0.178552              21.6738       \n",
      "\u001b[J923         0.091271    0.217215              21.7082       \n",
      "\u001b[J924         0.0927501   0.231763              21.7442       \n",
      "\u001b[J925         0.0702059   0.178675              21.7782       \n",
      "\u001b[J926         0.0861533   0.211174              21.8157       \n",
      "\u001b[J927         0.0617063   0.225734              21.8519       \n",
      "\u001b[J928         0.0791319   0.184608              21.8888       \n",
      "\u001b[J929         0.0798256   0.19926               21.9221       \n",
      "\u001b[J930         0.0822546   0.232137              21.9585       \n",
      "\u001b[J931         0.0934054   0.163598              21.9963       \n",
      "\u001b[J932         0.0609861   0.231367              22.0286       \n",
      "\u001b[J933         0.0834945   0.234232              22.0613       \n",
      "\u001b[J934         0.0806282   0.186877              22.0933       \n",
      "\u001b[J935         0.0890312   0.171875              22.1276       \n",
      "\u001b[J936         0.0735871   0.335618              22.168        \n",
      "\u001b[J937         0.0913505   0.193034              22.2024       \n",
      "\u001b[J938         0.0874972   0.176633              22.2385       \n",
      "\u001b[J939         0.0747618   0.224109              22.2725       \n",
      "\u001b[J940         0.0851487   0.237144              22.3037       \n",
      "\u001b[J941         0.0717164   0.176336              22.339        \n",
      "\u001b[J942         0.0858462   0.227522              22.3792       \n",
      "\u001b[J943         0.0743894   0.211396              22.4169       \n",
      "\u001b[J944         0.077273    0.201056              22.4524       \n",
      "\u001b[J945         0.0762802   0.185269              22.4856       \n",
      "\u001b[J946         0.102228    0.201911              22.5203       \n",
      "\u001b[J947         0.0556007   0.181365              22.5546       \n",
      "\u001b[J948         0.0756703   0.245595              22.5914       \n",
      "\u001b[J949         0.0840054   0.21941               22.6252       \n",
      "\u001b[J950         0.069031    0.168001              22.6607       \n",
      "\u001b[J951         0.0795543   0.207795              22.6945       \n",
      "\u001b[J952         0.083678    0.227875              22.7266       \n",
      "\u001b[J953         0.0771888   0.197702              22.7601       \n",
      "\u001b[J954         0.0802443   0.186579              22.7975       \n",
      "\u001b[J955         0.0728358   0.201777              22.8314       \n",
      "\u001b[J956         0.0763665   0.219118              22.8691       \n",
      "\u001b[J957         0.0760378   0.236257              22.9051       \n",
      "\u001b[J958         0.07376     0.170118              22.9399       \n",
      "\u001b[J959         0.0811251   0.215857              22.9749       \n",
      "\u001b[J960         0.0750631   0.216755              23.0106       \n",
      "\u001b[J961         0.0706131   0.196646              23.0467       \n",
      "\u001b[J962         0.078495    0.181296              23.0792       \n",
      "\u001b[J963         0.0737623   0.243457              23.1129       \n",
      "\u001b[J964         0.0794464   0.197125              23.1464       \n",
      "\u001b[J965         0.0715122   0.188666              23.1817       \n",
      "\u001b[J966         0.0687126   0.200197              23.2201       \n",
      "\u001b[J967         0.0731878   0.232847              23.2542       \n",
      "\u001b[J968         0.0826735   0.209356              23.2887       \n",
      "\u001b[J969         0.077236    0.218563              23.3225       \n",
      "\u001b[J970         0.0875192   0.158335              23.3552       \n",
      "\u001b[J971         0.0799278   0.249049              23.3903       \n",
      "\u001b[J972         0.0824628   0.183952              23.4284       \n",
      "\u001b[J973         0.0750127   0.19624               23.4658       \n",
      "\u001b[J974         0.0759966   0.202254              23.501        \n",
      "\u001b[J975         0.0742474   0.23092               23.5346       \n",
      "\u001b[J976         0.0691586   0.209213              23.5716       \n",
      "\u001b[J977         0.075686    0.177499              23.6053       \n",
      "\u001b[J978         0.0791836   0.198664              23.6436       \n",
      "\u001b[J979         0.0785874   0.220785              23.6795       \n",
      "\u001b[J980         0.0706006   0.210369              23.7133       \n",
      "\u001b[J981         0.0658616   0.194795              23.7481       \n",
      "\u001b[J982         0.0697288   0.204277              23.7824       \n",
      "\u001b[J983         0.0740289   0.200938              23.8174       \n",
      "\u001b[J984         0.0732323   0.213888              23.854        \n",
      "\u001b[J985         0.0740807   0.200527              23.8883       \n",
      "\u001b[J986         0.0732548   0.19549               23.9261       \n",
      "\u001b[J987         0.0750781   0.205505              23.9646       \n",
      "\u001b[J988         0.0658452   0.235114              24.0005       \n",
      "\u001b[J989         0.0845126   0.193522              24.0383       \n",
      "\u001b[J990         0.0691799   0.230713              24.0769       \n",
      "\u001b[J991         0.0743851   0.198889              24.1138       \n",
      "\u001b[J992         0.072733    0.214998              24.1478       \n",
      "\u001b[J993         0.0768903   0.208801              24.1817       \n",
      "\u001b[J994         0.0704936   0.186742              24.2178       \n",
      "\u001b[J995         0.0753793   0.22132               24.2563       \n",
      "\u001b[J996         0.0645037   0.209353              24.2952       \n",
      "\u001b[J997         0.0714798   0.202206              24.3295       \n",
      "\u001b[J998         0.0738631   0.199553              24.3606       \n",
      "\u001b[J999         0.0769487   0.188117              24.3994       \n",
      "\u001b[J1000        0.071564    0.22244               24.434        \n"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の経過データを読み込み\n",
    "\n",
    "Trainerを設定する際に以下のようにout='resut'と指定していました。\n",
    "これにより、学習の結果（上記に表示されているmain/lossやvalidation/main/loss）がresult/logに保存されています。\n",
    "\n",
    "> trainer = training.Trainer(updater, (epoch, 'epoch'), out='result')\n",
    "\n",
    "学習後には、下記のようにlogというファイルが保存されています。\n",
    "<img src=\"./images/08.jpg\" width=\"400\" />\n",
    "\n",
    "こちらのファイルの中身をエディター（メモ帳）で確認してみると、下記のように格納されていました。\n",
    "<img src=\"./images/09.png\" width=\"400\" />\n",
    "\n",
    "こちらのlogファイルを読み込み、可視化してみましょう。\n",
    "\n",
    "ファイルの読み込みは以下のように簡単に実装できます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('result/log') as f:\n",
    "     logs = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こちらをlogsという変数名で格納しておくと、辞書型として以下のようにデータにアクセスできます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の経過をプロット\n",
    "まず、プロットするためにリストに変換しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_train, result_test = [], []\n",
    "for log in logs:\n",
    "    result_train.append(log['main/loss'])  # 訓練データ\n",
    "    result_test.append(log['validation/main/loss'])  # 訓練データ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こちら、Pythonの書き方に慣れている人は以下のように書くこともできます（こちらがPython流）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_train = [ log['main/loss'] for log in logs ]\n",
    "result_test  = [ log['validation/main/loss'] for log in logs ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こちらだと、空のリストを定義して（[ ]）、そのリストに要素を一つずつ追加して（append）、といった処理を書かなくても良いため、シンプルに書けます。\n",
    "ただし、最初からこちらの書き方だと難しいため、慣れるまでは前者の書き方で、慣れてきたら後者の書き方にしていきましょう。\n",
    "\n",
    "プロットはこれまで同様にmatplotlibを使用しますが、今回は凡例（legend）を追加しておきましょう。\n",
    "plotのオプションにlabelを追加し、plt.legend()を追加することで、凡例が追加されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0EVEFoj/DwAyf/wKoQPxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113163198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result_train, label='train')  # 訓練データ\n",
    "plt.plot(result_test,  label='test')  # 検証データ\n",
    "plt.legend()  # 凡例表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こちらを確認すると、訓練データの損失関数の値が下がりながら、検証データの損失関数の値も下がっているため、**オーバーフィッティング（過学習）**も起こっておらず、理想的な学習ができていることがわかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. ニューラルネットの学習テクニック (15分)\n",
    "* NNの最適化手法(Momentum法(MomentumSGD)/AdaGrad/Adam)\n",
    "* NNの正則化手法(Dropout)\n",
    "* 勾配消失問題\n",
    "* XavierとHeの初期化\n",
    "* Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizerの種類\n",
    "既に登場したSGDやAdam含め、Optimizerにはいくつか種類があります。  \n",
    "詳細は[こちら](https://docs.chainer.org/en/stable/reference/optimizers.html)を御覧ください。\n",
    "<img src=\"./images/10.png\" width=\"400\" />\n",
    "\n",
    "各手法の数式と違いに関しては、下記の記事がわかりやすいです。\n",
    "\n",
    "[Optimizer : 深層学習における勾配法について](http://qiita.com/tokkuman/items/1944c00415d129ca0ee9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD（確率的勾配降下法）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optimizers.SGD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モーメンタム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optimizers.MomentumSGD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optimizers.AdaGrad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNの正則化手法(Dropout)\n",
    "実データを扱う際にかなり高確率で遭遇する現象として、**NNの過学習（オーバーフィッティング）**があります。\n",
    "<img src=\"./images/11.png\" width=\"400\" />\n",
    "\n",
    "こちらの対策として、**ドロップアウト**があるので、ぜひ覚えておきましょう。\n",
    "ドロップアウトは、train時に指定してあげるだけで完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MLP: Multi-layer Perceptron\n",
    "class MLP(chainer.Chain):\n",
    "    \n",
    "    def __init__(self, n_units1, n_units2, n_output):\n",
    "        super().__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(None, n_units1)\n",
    "            self.l2 = L.Linear(None, n_units2)\n",
    "            self.l3 = L.Linear(None, n_output)\n",
    "            \n",
    "    def __call__(self, x, train=True):\n",
    "        if train:\n",
    "            h1 = F.dropout( F.relu(self.l1(x)), ratio=0.2)\n",
    "            h2 = F.dropout( F.relu(self.l2(h1)), ratio=0.2 )\n",
    "            return self.l3(h2)\n",
    "        else:\n",
    "            h1 = F.relu(self.l1(x))\n",
    "            h2 = F.relu(self.l2(h1))\n",
    "            return self.l3(h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 勾配消失問題とHeの初期化\n",
    "reluを使用する際には、Heを使うのが良いと言われていたりする（こちらは経験則）。  \n",
    "詳しくは、機械学習プロフェッショナルシリーズ参照。\n",
    "\n",
    "Chainerで通常のLink宣言では、パラメータの値はランダムに決められるため、こちらをHeベースの初期値にする方法を紹介します。\n",
    "\n",
    "まず、initializer として、以下を定義しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initializer = chainer.initializers.HeNormal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こちらの initializer を link 宣言の際に、initialWのオプションで指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.links.connection.linear.Linear at 0x1131f4470>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chainer.links.Linear(100, 100, initialW=initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "性能を向上させる一つの選択肢として、Batch Normalizationがあります。  \n",
    "こちらをChainerで実装することも非常に簡単です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MLP: Multi-layer Perceptron\n",
    "class MLP(chainer.Chain):\n",
    "    \n",
    "    def __init__(self, n_units1, n_units2, n_output):\n",
    "        super().__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(None, n_units1)\n",
    "            self.l2 = L.Linear(None, n_units2)\n",
    "            self.l3 = L.Linear(None, n_output)\n",
    "            \n",
    "    def __call__(self, x):\n",
    "            h1 = L.BatchNormalization( F.relu(self.l1(x)) )\n",
    "            h2 = L.BatchNormalization( F.relu(self.l2(h1)) )\n",
    "            return self.l3(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
